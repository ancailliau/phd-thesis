% !TEX root = thesis.tex

\startcomponent chap-3

\product thesis
\environment common

\startchapter
	[reference=chap:proba-framework, 
	 title={A Probabilistic Framework for Goal-Oriented Requirements Engineering}]

    \framed[frame=off,bottomframe=on,boffset=2em,toffset=0em]
    	{\vbox{\startsubject[title={Content}]\placesummary}\stopsubject}
	\vskip1.5em
    
    % objectives of the framework
    
    % formal semantics for the statements
    
    % measurable statements
    
    % model based and probabilistic requirements
    
    This chapter presents the precise definition of probabilistic goals and probabilistic 
    obstacles, as well as the mathematical foundations these definitions rely on.
    
	Probability is a widely-used term with various interpretations. Two major interpretation
	co-exists, the frequentist interpretation where a probability is a physical measure
	for something to happen, and the bayesian interpretation where a probability is a
	measure on how strong someone believe a claim. For most of the thesis, and this
	chapter in particular, we focus on
	the frequentist approach where goals are satisfied at a persistent rate in the long
	run. \in{Chapter}[chap:knowledge-uncertainty] we will focus on the second interpretation
	and its connection to the first one.
    
    Probabilistic goals and obstacles relies on the
    use of specific languages such as PCTL and PCTL* for a clear and precise specification of their 
    probabilistic intent. A precise definition of probabilistic goals
    and obstacles requires a definition of their formal semantic.
    Such formal semantic relies on the underlying\emdash{}and not necessarily explicit
    \emdash{}probabilistic behavior model of the system, and the notion of 
    measurable statement. Measurability is based on $\sigma$-algebra and probability 
    spaces. This formal prelude forms the formal foundations for probabilistic
    goals and obstacles.
    
    In a non-probabilistic framework, goals are required to be always satisfied. The
    probabilistic framework bring some nuance to such claims, as probabilistic goals
    are, by nature, not always satisfied. Evidently, not all satisfaction rates are 
    acceptable as laws, regulations, or best practices imposes bounds on these
    rates. Precise definition of probabilistic goals often requires their formalisation.
    Such formalisation, although essential for automated reasoning,
    might be tedious and error-prone. Specification patterns ease this process, encoding
    frequent and standard statement structures.
    As in the non-probabilistic framework, probabilistic goals are organized 
    in an AND/OR-graph by refinements. These refinements shall be complete, consistent
    and ideally minimal. Refinement patterns encodes known and proved decomposition 
    tactics, facilitating the construction of these AND/OR-graphs
    
    Obstacles are the preconditions to the non-satisfaction of goals. The satisfaction
    rate of a goal is therefore tightly bound the satisfaction rate of an obstacle.
    As goals, obstacles can be formalized, e.g. by using known specification patterns,
    and are organized in and AND/OR-graph.
    
    XXX   
    
    \startsection
    	[reference=sec:formal-foundation, 
	     title={Formal Foundations}]
	     
    	\in{Section}[sec:sigma-algebra] presents the mathematical foundation for the
        precise semantic definition of probabilistic goals and obstacles. 
        \in{Section}[sec:probabilistic-behavior] presents the underlying behavioral
        model and precisely defines the notion of measurable statement.
        Last, \in{Section}[sec:formal-spec-probabilistic-goal] presents specific
        languages for specifying probabilistic assertions, namely PCTL and PCTL*.
                
        %Probabilistic goals can be formalized as Probabilistic Computation 
        %Tree Logic* (PCTL*) assertions. PCTL* is a branching-time temporal logic 
        %based on the logic PCTL and CTL \cite{Bai08a}. 
        %
        %If the number of possible behaviors is infinite, our intuitive 
        %definition presented above is not well-formed as both the numerator and 
        %denominator tends towards infinity. In addition, the rate at which we 
        %observe each behavior impacts the satisfaction rate of our goal, and it is 
        %not taken into account in our naïve definition. In our example, if $p_4$ is 
        %observed more often than $p_3$, our satisfaction rate will be lower. 
        %Although intuitive,  goal satisfaction rate requires a sound formalisation 
        %of the probabilities for sets of paths. This formalisation is based on $
        %\sigma$-algebra and probability spaces. Our presentation is inspired from 
        %\cite[Bai08a]. 
			
        \startsubsection
         	[reference=sec:sigma-algebra,
			 title={$\sigma$-algebra and Probability Spaces}]
           
			Intuitively, for the definition to work, the set of possible path needs to 
			have a "size" so that we can "compare" set of paths to all possible paths. 
			Formally, the set of possible paths needs to be measurable. This is captured 
			by attaching to the set of possible paths a collection of subsets of 
			possible paths. The collection of subset is called a $\sigma$-algebra. A $
			\sigma$-algebra over a set of possible path $X$ is a collection $\Sigma$ of 
			subset of possible paths such that the collection contains the empty set, is 
			closed under complementation and countable unions:
			
            \startitemize[packed]
            	\item $\emptyset \in \Sigma$
            	\item if $Paths \in \Sigma$, then $\overbar{\Sigma} = \Sigma \textbackslash Paths$
	            \item if $Paths_1, Paths_2, ... \in \Sigma$, then $\bigcup_{n\geq1}  Paths_i\in\Sigma$
            \stopitemize
            
            Once we exhibited such a collection of subsets of possible paths, 
			the set of all possibles paths is said \italic{measurable}. The powerset 
			$2^{Paths}$ yield a $\sigma$-algebra over $Path$. For the following, 
			otherwise specified explicitly, we consider the power set over the possible 
			paths as the $\sigma$-algebra.
            
            To attach a probability to the measurable set, the $\sigma$-algebra 
			$\Sigma$ must be equipped with a probability measure. A \italic{probability 
			 measure} is function that maps the subsets to $\{0,1\}$ such that
            \startitemize[packed]
            	\item The probability of the subset containing all the paths is 1, 
		            \startformula
        			    Pr(Paths) = 1
		            \stopformula
	            \item if $Path_1, Paths_2$ are subsets that do not share a possible 
					 path, then their probability can be computed by combining the probability on 
					 the subsets:
		            \startformula
        			    Pr(\bigcup_{n\geq1}Paths_i) = \sum_{n\geq1} Pr(Paths_i)
		            \stopformula
            \stopitemize
            
            \startexample
            
        	    Consider only the behaviors $p_3$ and $p_4$. 
            
            	The set containing the four following subsets: \{\}, \{$p_3$\}, 
				\{$p_4$\}, \{$p_3, p_4$\} is a proper $\sigma$-algebra defined 
				over $\Sigma = \{p_3, p_4\}$. We can define a probability measure 
				over this collection of set of paths:
	
	            \startformula \startalign [n=2,align={right,left}]
    	        	\NC Pr(\{\}) 			\NC = 0, 	\NR
        	    	\NC Pr(\{p_3\}) 		\NC = .4, 	\NR
            		\NC Pr(\{p_4\}) 		\NC = .6, 	\NR
            		\NC Pr(\{p_3,p_4\})) 	\NC = 1		\NR
	            \stopalign \stopformula
            
    	        Over these two behaviors, only $p_3$ satisfy our requirement 
			    $HighWater \Rightarrow X PumpOn$. According our probability measure, the 
				satisfaction rate for the requirement over these two behaviors is 
				$Pr(\{p_3\}) = .4$.
            \stopexample
            
		\stopsubsection
		
		\startsubsection
			[reference=sec:probabilistic-behavior,
			 title={Probabilistic behavior Model and Measurable Statements}]
            
			The 
		    characterisation above is rather abstract; However, if the behaviors of the 
		    system can be captured by a Markov Chain, there exists a $\sigma$-algebra 
            for that Markov Chain. Explicit computation procedures for the probability 
            measure over that $\sigma$-algebra are available and will be explored in 
            \in{chapter}[runtime].
                    
            A Markov Chain is a state machine where transitions between states 
            are decorated by probabilities. The successor of a node is chosen according 
            the probability on the transitions. The probabilities from moving to one 
            state to another does not depend on the path from the initial state to the 
            state but only depend on the state. This property is also known as 
            \italic{memoryless} property. 
            
            \startdefinition[def:mc]{Markov Chain}
                A Markov Chain is a tuple 
                \startformula
                	\langle States, \bold{P}, Init, AP \rangle
                \stopformula
                where
                \startitemize[packed]
                    \item $States$ is the set of states,
                    \item $\bold{P} : States \times States \rightarrow [0,1]$ is the 
            			transition probability function such that 
                    \startformula 
                    \sum_{s'\in S} \bold{P}(s, s') = 1
                    \stopformula
                    \item $Init : State \rightarrow [0, 1]$ is the initial distribution,
                    \item $AP$ is the set of atomic proposition and $L : State \rightarrow 2^{AP}$ 
                    	is the labelling function.
                \stopitemize
            \stopdefinition
            
            The transition probability function $\bold{P}(s,s')$ specifies the 
            state $s$ the probability to move to the state $s'$ in one step. The initial 
            distribution specifies the possible initial states, with their respective 
            probabilities.
            
            A Markov Chain is often depicted by its graph where states are nodes 
            and transitions are edges. Edges are annotated with the corresponding 
            probability. Probability $1$ on edges are omitted. \in{Figure}[fig:incorrect-pctl] 
            shows a Markov chain with 2 states: $PumpOff$ and $PumpOn$.
            
            \placefigure[here]
            	[fig:incorrect-pctl]
            	{A simple system}
            	{\startMPcode
            		def connectcircle (expr a, b, circle_size) =
            			numeric ang; ang := angle(b-a);
                		drawarrow (a + getanchor(ang, circle_size))
                				  -- (b - getanchor(ang, circle_size));
            		enddef ;
            		
            		def getanchor (expr ang, circle_size) =
            			(cosd(ang) * circle_size/2, sind(ang) * circle_size/2)
            		enddef ;
            	
            		pair a, b, c;
            		numeric circle_size;
            		circle_size := 8mm;
            		
            		width := 1.4cm;
            		height := 6mm;
            		
            		a := (0, 0);
            		c := (3cm, 0);
            		
            		draw unitsquare xscaled width yscaled height smoothed .5mm 
						shifted (c-(width/2,height/2)) withcolor black;
            		draw unitsquare xscaled width yscaled height smoothed .5mm 
						shifted (a-(width/2,height/2)) withcolor black;
            		
            		label.bot(btex $.5$ etex, a+(c-a)/2);
            		label.bot(btex $.5$ etex, a + getanchor(-90, circle_size) * 2);
            		
            		label(btex PumpOff etex scaled .75, a);
            		label(btex PumpOn etex scaled .75, c);
            		
            		drawarrow 
            			a + getanchor(135, circle_size) * 2 
            			-- a + (getanchor(135, circle_size) yscaled 0 + (0,height/2));
            		
            		numeric ang; ang := angle(c-a);
                	drawarrow (a + (getanchor(ang, circle_size) xscaled 0 + (width/2, 0)))
                			  -- (c - (getanchor(ang, circle_size) xscaled 0 + (width/2, 0)));
            		
            		drawarrow 
            			c + (getanchor(135, circle_size) yscaled 0 + (0,height/2)) .. 
            			controls (c + getanchor(135, circle_size * 3)) 
            			and (a + getanchor(45, circle_size * 3)) ..
            			a + (getanchor(45, circle_size) yscaled 0 + (0,height/2));
            			
            		drawarrow 
            			a + (getanchor(-45, circle_size) yscaled 0 - (0,height/2))
            			.. a + getanchor(-90, circle_size) * 2
            			.. a + (getanchor(-135, circle_size) yscaled 0 - (0,height/2));
            	\stopMPcode}
            
            
            With a Markov Chain, $Paths$ is the set of infinite sequence of 
            states $s_0s_1s_2s_3...$ such that $P(s_i,s_{i+1}) > 0$. The $\sigma$-
            algebra associated with the Markov chain is the smallest $\sigma$-algebra 
            that contains all the cylinder sets spanned by all finite path fragments 
            from the Markov Chain. 
            
            A cylinder set spanned by a finite path $\hat\pi$ is the set of 
    		infinite paths with the prefix $\hat\pi$.
            \startformula
            	Cyl(\hat\pi) = \{\pi \in Paths\ |\ \hat\pi \in pref(\pi)\}
            \stopformula
            where $pref(\pi)$ denotes all the prefixes for the path $\pi$.
            
            The probability measure associated with the $\sigma$-algebra is 
    		given by
            \startformula
            	Pr(Cyl(s_0...s_n)) = Init(s_0)\cdot\prod_{0\leq i<n}\bold{P}(s_i, s_{i+1})
            \stopformula
            
            \startexample
	            XXX
            \stopexample
            
            \noindent\bold{Probabilistic Goals.} Based on the formal definition 
            of probability measure over paths, the satisfaction rate of a goal is 
            formally defined as:
            
            \startdefinition[dfn:satisfactionrate]{Satisfaction Rate}
                The satisfaction rate of a goal $\square\phi$, is defined as 
                $Pr(\{\pi \in Paths(s)\ |\ \pi \models \phi\})$ 
                where $Paths(s)$ are the possible paths in the system starting in any possible state $s$.
            \stopdefinition	
            
            We assume that the behavior of the system can be captured by a 
    		Markov Chain, even if not explicitly provided. Extending the definition 
    		above, $P(G|H)$ is formally characterized as:
            
            \startformula
            	Pr(\{\pi \in \{\pi'\in Paths\ |\ \pi' \models H\}\ |\ \pi \models G \})
            \stopformula
            
            We focus on non-vacuous satisfaction of our requirements. The 
            problem of antecedent failure was recognized to be a problem is application 
            of formal verification \cite[Bea94a]. Vacuous satisfaction potentially hides 
            faults in complex models as parts of the assertion are not necessary for the 
            satisfaction. Techniques exists to detect vacuity in formalized requirements 
            \cite[Kup03a]. We assume that the requirements are not vacuously satisfied 
            by the system of interest.
            
            %The key idea behind the detection is to replace sub-formula by 
    		%$True$ or $False$ depending on their polarity and check the transformed 
			%assertion against the model. 
            
            %\startexample
            %Assume the requirement $HighWater \Rightarrow_{\geq 95\%} 
			%\lozenge_{\leq 2min} PumpOn$.
            %\startitemize
            %\item Replacing $HighWater$ by $True$ leads to $Pr_1[\square 
            %P_{\geq 95\%}[\lozenge_{\leq 2min} PumpOn]]$. If this is true in our system, 
            %it means that the motor is always turned on within two minutes, whether the 
            %water is high or not does not impact the satisfaction, and our requirement 
            %is vacuously satisfied.
            
            %\item Replacing $\lozenge_{\leq 2min} PumpOn$ by $False$ leads to 
            %$Pr_1[\square P_{\geq 95\%}[\neg HighWater]] \equiv Pr_1[\square \neg 
            %HighWater]$. If this is true in our system, water is never high, and our 
            %requirement is vacuously satisfied.
            %\stopitemize
            %\stopexample
            
            
			
%			The probability of satisfaction of a goal $C \Rightarrow \Theta T$ 
%			is the proportion between (a) the number of possible behaviors satisfying 
%			the goal's antecedent $C$ and consequent $\Theta T$ and (b) the number of 
%			possible behaviors satisfying the condition $C$.
            
            %For a behavioral goal $C\Rightarrow\Theta T$, we are obviously 
            %interested in non-vacuous satisfaction, leaving aside those trivial cases 
            %where the goal is satisfied due to C being false. We therefore focus our 
            %attention on behaviors where the goal antecedent C is satisfied.
        
        \stopsubsection
    
    	\startsubsection
			[reference=sec:formal-spec-probabilistic-goal,
			 title={Formal Specification of Probabilistic Assertions}]
        
            A PCTL formula specify conditions on states, on the contrary to LTL 
            formula specifying conditions on paths. The main difference with CTL 
            formulas is the quantification over paths. The interpretation of a PCTL 
            formula over a state is boolean, either a state satisfy the formula, either 
            not. In CTL formulas, paths are universally quantified \emdash i.e.  all 
            paths starting from the state satisfy the formula\emdash or existentially 
            quantified \emdash i.e. there is a path starting from the state that satisfy 
            the formula \emdash. PCTL formulas can be seen as the quantitative 
            counterpart of CTL, paths are quantified according their likelihood. 
            
            PCTL state formulas are built from the following grammar:
            
            \startformula
            	\phi = true\ |\ a\ |\ \phi_1\wedge\phi_2\ |\ \neg\phi\ |\ {\blackboard{}P}_I(\psi)
            \stopformula
        
            where $a$ is an atomic proposition $a\in AP$ and $I \subseteq [0,1]$ 
    		is a non-empty interval. The path formulas are built from the following 
    		grammar:
            
            \startformula
            	\psi = \bigcirc\phi\ |\ \phi_1U\phi_2\ |\ \phi_1U^{\leq n}\phi_2
            \stopformula
            
            For convenience, intervals for the probabilistic operators are often 
    		abbreviated, e.g. ${\blackboard{}P}_{\geq .5}(\psi)$ denotes 
    		${\blackboard{}P}_{[.5,1]}(\psi)$, ${\blackboard{}P}_1(\psi)$ denotes 
    		${\blackboard{}P}_{[1,1]}(\psi)$, etc.
            
            The operator eventually ($\lozenge\phi$) can be derived, as usual, 
    		from the until operator : $true\ U\ \phi$. The operator always $\square\phi$ 
    		can also be derived from the until operator $\neg(true\ U\ \phi)$. Note that 
    		the duality between the two operators and their lower and upper bound.
        
            \startformula
            	{\blackboard{}P}_{\leq p}(\lozenge\phi) = {\blackboard{}P}_{> 1-p}(\square\neg\phi)
            \stopformula
        
            More generaly, we have 
        
            \startformula
    	        {\blackboard{}P}_{\leq p}(\psi) = \neg{\blackboard{}P}_{> 1 - p}(\psi)
            \stopformula
        
            The operator weak until $\phi_1\ W\ \phi_2$ is equivalent to 
            $(\phi_1\ U\ \phi_2) \vee \square \phi_1$ and the operator release 
            $\phi_1\ R\ \phi_2$ is equivalent to $\neg(\neg\phi_1\ U\ \neg\phi_2)$. 
            
            In our framework, PCTL formulas are interpreted over states and 
    		paths of an underlying Markov Chain. The satisfaction relation over states 
    		is defined by
            
            \startformula\startalign[n=3,align={left, middle, left}]
            	\NC s\models a 							\NC \hskip5mm\text{iff}\hskip5mm 	\NC a\in L(s) \NR
            	\NC s\models \phi_1\wedge\phi_2 		\NC \hskip5mm\text{iff}\hskip5mm 	\NC s\models\phi_1 \text{ and }s\models\phi_2 \NR
            	\NC s\models \neg\phi 					\NC \hskip5mm\text{iff}\hskip5mm 	\NC s\not\models \phi \NR
            	\NC s\models {\blackboard{}P}_I(\psi) 	\NC \hskip5mm\text{iff}\hskip5mm 	\NC Pr(\{\phi \in Paths(s)\ |\ \pi\models\phi\}) \in I \NR
            \stopalign\stopformula
          
            where $Paths(s)$ denotes all paths starting with the state $s$. And 
    		the satisfaction relation over paths is defined as
            
            \startformula\startalign[n=3,align={left, middle, left}]
            	\NC \pi\models \bigcirc\phi 			\NC \hskip5mm\text{iff}\hskip5mm 	\NC \pi_1 \models \phi \NR
            	\NC \pi\models \phi_1U\phi_2 			\NC \hskip5mm\text{iff}\hskip5mm 	\NC \text{ exists } i \geq 0 \text{ s.t. } \pi_i\models\phi_2 \NR
            	\NC\NC\NC\text{ and for all } 0 \leq k < i \text{, } \pi_k\models\phi_1\ \NR
            	\NC \pi\models \phi_1U^{\leq n}\phi_2 	\NC \hskip5mm\text{iff}\hskip5mm 	\NC \text{ exists } 0 \geq i \geq n \text{ s.t. } \pi_i\models\phi_2 \NR
            	\NC\NC\NC\text{ and for all } 0 \leq k < i \text{, } \pi_k\models\phi_1\ \NR
            \stopalign\stopformula
            
            The probabilistic operator $Pr_I(\phi)$ specifies that the 
    		likelihood for the path satisfying the path-formula $\phi$ lies in the 
    		interval $I\subset [0,1]$. 
                    
            The logic PCTL* extends the logic PCTL by allowing boolean 
    		combinations of path formulas. PCTL* is more expressive that PCTL as it 
    		includes LTL. Path formulas are built according the following grammar:
            
            \startformula
            	\psi = \phi\ |\ \psi_1\wedge\psi_2\ |\ \bigcirc\phi\ |\ \phi_1U\phi_2\ |\ \phi_1U^{\leq n}\phi_2
            \stopformula
            
            The other operators $\lozenge$, $\square$, $W$, $R$ are defined as 
    		previously. The satisfaction relation of PCTL is extended for the new 
    		grammar:
            \startformula\startalign[n=3,align={left, middle, left}]
            	\NC \pi\models \psi 				\NC \hskip5mm\text{iff}\hskip5mm 	\NC \pi_0 \models \psi \NR
            	\NC \pi\models \phi_1\wedge\phi_2 	\NC \hskip5mm\text{iff}\hskip5mm 	\NC \pi\models\phi_1\text{ and }\pi\models\phi_2 \NR
            \stopalign\stopformula
            
            The set of paths specified by a PCTL or a PCTL* formula is 
    		measurable (see \cite[Bai08a] for a proof), ensuring that our semantic of 
    		probabilistic goal is well-defined when goals are formalized.
        
        \stopsubsection
    
    \stopsection
    
    \startsection
    	[reference=sec:probabilistic-goal,
		 title={Probabilistic Goals}]

		Previous section introduced how we can specify and measure probabilistic 
		assertions. This section introduces probabilistic goals, leveraging the 
		formal foundations.
    
    	This section is organized as follow. 
        \in{Section}[sec:defining-probabilistic-goals] defines probabilistic goals
        and discusses how satisfaction arguments for goal refinements are generalized. 
		\in{Section}[ref:independence-goals] discusses goal independence.
        Last, \in{Section}[sec:patterns-probabilistic-goals] provides common 
        specification and refinement patterns for probabilistic goals.
    
    	\startsubsection
			[reference=sec:defining-probabilistic-goals,
			 title={Defining and Modelling Probabilistic Goals}]
    
	        As seen before, a non-probabilistic goal defines a maximal set of intended 
			behaviors. In particular, behavioral goal $C\Rightarrow\Theta T$ defines
			the set of behaviors where all states satisfy $C\rightarrow\Theta T$.
			Intuitively, in a probabilistic framework, 
			a state satisfy $C \rightarrow \Theta T$
			at a given rate, depending on the proportion between behaviors, 
			starting in that state, satisfying the property and not satisfying 
			the property. The satisfaction rate for a goal $C\Rightarrow\Theta T$
			is the greatest rate the system can guarantee, i.e. the maximal
			rate such that all states have a greater chance to satisfy 
			$C\rightarrow\Theta T$.
			
			Note that we are not interested in the proportion of behaviors where
			$C\Rightarrow\Theta T$ is satisfied among all possible behaviors. In fact,
			the chance of observing a behavior satisfying $C\Rightarrow\Theta T$
			tends towards $0$ in the long run. Imagine a very small system sending
			messages with a probability of $\vfrac{9}{10}$ to deliver a message, as the following
			figure suggest:
			
			\vskip1em\midaligned{\startMPcode
            		def connectcircle (expr a, b, circle_size) =
            			numeric ang; ang := angle(b-a);
                		drawarrow (a + getanchor(ang, circle_size))
                				  -- (b - getanchor(ang, circle_size));
            		enddef ;
            		
            		def getanchor (expr ang, circle_size) =
            			(cosd(ang) * circle_size/2, sind(ang) * circle_size/2)
            		enddef ;
            	
            		pair a, b, c, d;
            		numeric circle_size;
            		circle_size := 8mm;
            		
            		width := 1.4cm;
            		height := 6mm;
            		
            		a := (2.5cm, 1cm);
            		b := (2.5cm, 0cm);
            		c := (0cm, 0cm);
            		d := (5cm, 0cm);
            		
            		draw unitsquare xscaled width yscaled height smoothed .5mm 
						shifted (a-(width/2,height/2)) withcolor black;
            		draw unitsquare xscaled width yscaled height smoothed .5mm 
						shifted (b-(width/2,height/2)) withcolor black;
            		draw unitsquare xscaled width yscaled height smoothed .5mm 
						shifted (c-(width/2,height/2)) withcolor black;
            		draw unitsquare xscaled width yscaled height smoothed .5mm 
						shifted (d-(width/2,height/2)) withcolor black;
            		
            		label(btex Start etex scaled .75, a);
            		label(btex Try etex scaled .75, b);
            		label(btex Delivered etex scaled .75, c);
            		label(btex Lost etex scaled .75, d);

					drawarrow a - (0, height/2) -- b + (0, height/2);
					drawarrow b + (width/2, 0) .. b + (d-b)/2 + (0, height/2) .. d - (width/2, 0);
					drawarrow d - (width/2, 0) .. b + (d-b)/2 - (0, height/2) .. b + (width/2, 0);
					drawarrow b - (width/2, 0) -- c + (width/2, 0);
					drawarrow c + (0, height/2) .. controls (c + (0, 1cm))
								and (a - (1cm, 0)) .. a - (width/2, 0);
								
            		label.top(btex $\frac{1}{10}$ etex scaled .75, b + (d-b)/2 + (0, height/2));
            		label.top(btex $\frac{9}{10}$ etex scaled .75, b + (c-b)/2);
            	\stopMPcode}\vskip1em
			
			To satisfy $Try\Rightarrow\bigcirc Delivered$, every message must be successfully
			delivered. The probability to deliver one message is $\vfrac{9}{10}$,
			and $n$ messages is $\vfrac{9}{10}^n$. When
			$n \rightarrow \infty$, $\vfrac{9}{10}^n \rightarrow 0$. However, the probability
			to satisfy $Try\rightarrow\bigcirc Delivered$ is $1$ in \italic{Start},
			\italic{Delivered} and \italic{Lost} states, and $\vfrac{9}{10}$ in
			\italic{Try} state. Therefore, the satisfaction rate for $Try\Rightarrow\bigcirc Delivered$
			is $\vfrac{9}{10}$.
            
            
            \startdefinition[dfn:satisfaction-rate]{Satisfaction Rate}
              	The satisfaction rate of a goal $C\Rightarrow \Theta T$ 
               	is the maximal probability $p$ such that
				\startformula
					Pr(\lbrace\pi\in Paths(s)\ |\ \pi\models C\rightarrow \Theta T\rbrace) \geq p
				\stopformula
				in all states $s$.
            \stopdefinition	
            
            \startexample
%    			Consider a very simple system for a mine pump where we only have 4 
%    			possible finite behaviors of two states:
%            
%        	    \startformula \startalign
%            	 	\NC p_1 \NC = (LowWater, PumpOff), (LowWater, PumpOff) \NR
%             		\NC p_2 \NC = (HighWater, PumpOff), (LowWater, PumpOn) \NR
%    	         	\NC p_3 \NC = (HighWater, PumpOff), (HighWater, PumpOn) \NR
%        	    	\NC p_4 \NC = (HighWater, PumpOff), (HighWater, PumpOff) \NR
%    	        \stopalign \stopformula
%            
%          		The requirement $HighWater \Rightarrow X PumpOn$ is satisfied on 
%    			three of the possible behaviors: $p_1$, $p_2$, and $p_3$. The behavior 
%    			$p_4$ does not satisfy the requirement and $p_1$ vacuously satisfy our 
%    			requirement. Intuitively, if all behaviors are observed at the same rate, 
%    			the satisfaction rate for this requirement is $\fraction{2}{3}$.
            \stopexample
            
            A goal is fully satisfied if its probability of satisfaction is 
    		equal to 1. In the following, $P(G)$ denotes the satisfaction rate of a goal 
    		$G$. Extending the definition above, $P(G|H)$ denotes the satisfaction rate 
    		of $G$ over the behaviors satisfying the property $H$, i.e. the maximal
			probability $p$ such that 
			\startformula
				Pr(\lbrace\pi\in \lbrace \pi'\in Paths(s)\ |\ \pi' \models H\rbrace\ |\ \pi\models C\rightarrow \Theta T\rbrace) \geq p
			\stopformula
			in all states $s$.
            
            In our probabilistic framework, goals are annotated with an 
    		estimated satisfaction rate and a required degree of satisfaction. 
            
            \startdefinition[dfn:esr]{Estimated Satisfaction Rate}
            	The estimated satisfaction rate (ESR) of a goal is the satisfaction 
    			rate of this goal in view of its possible obstructions. It is computed from 
    			the goal/obstacle models.
            \stopdefinition
            
            \startexample
    	        In our running example, an allocated ambulance might not be 
    			mobilized for various reasons, e.g., the ambulance crew is unresponsive, the 
    			ambulance is not ready for its next mission, communication failure, etc. Due 
    			to such obstacles, there is a chance of this goal not being satisfied.
            \stopexample
            
            \startdefinition[dfn:rds]{Required Degree of Satisfaction}
    	        The required degree of satisfaction (RDS) of a goal is the minimal 
    			probability of satisfaction admissible for this goal. It is imposed by 
    			elicited requirements, existing regulations, standards, and the like.
            \stopdefinition
            
            Note that the previous situation of (non-probabilistic) goals 
    		recalled in \in{Section}[subsec:defining-goals] is generalized here; for 
    		such goals we have: $RDS (G) = 1$.
            
            Goals with a required degree of satisfaction can be formalized in PCTL*, as
            the minimal probability to achieve is known.
            For the following, we introduce the notation $C \Rightarrow_{\geq p} \Theta T$ 
            to denote 
            \startformula
	            Pr_1 [ \square Pr_{\geq p} [ C \rightarrow \Theta T ] ]
            \stopformula
            This notation is similar to the operator \quote{leads to} introduced in \cite[Han94a].
            This operator can also be formalized in PCTL,
            
            \startformula
            	Pr_1 [ \square (C \rightarrow Pr_{\geq p} [ \lozenge_{\bowtie t} T ]) ]
            \stopformula
            
            \startproposition
            	PCTL* formula $Pr_1 [ \square Pr_{\geq p} [ C \rightarrow \Theta T ] ]$ 
				and PCTL formula $Pr_1 [ \square (C \rightarrow Pr_{\geq p} [ \lozenge_{\bowtie t} T ]) ]$ are equivalent.
            \stopproposition
            
            \startproof
				(a) In a state where $C$ is true, the PCTL sub-formula 
                        $C \rightarrow Pr_{\geq p} [ \lozenge_{\bowtie t} T ]$ 
                        is reduced to $Pr_{\geq p} [ \lozenge_{\bowtie t} T ]$, 
                        and the PCTL* sub-formula 
                        $Pr_{\geq p} [ C \rightarrow \lozenge_{\bowtie t} T ]$ 
                        is reduced to $Pr_{\geq p} [ \lozenge_{\bowtie t} T ]$; 
                        both are trivially equivalent. 
                (b) In a state $s$ where $C$ is false, the PCTL sub-formula 
                    	$C \rightarrow Pr_{\geq p} [ \lozenge_{\bowtie t} T ]$ is reduced to $True$, 
            			and the PCTL* sub-formula $Pr_{\geq p} [ C \rightarrow \lozenge_{\bowtie t} T ]$ is reduced to $Pr_{\geq p} [ True ]$. The latter is equivalent to $True$:
                        
                        \startformula\startalign[n=3,align={left, left, right}]
                            \NC Pr_{\geq p} [ True ] \NC \equiv Pr (\{\pi \in Paths\ |\ \pi \models True\}) \geq p 	\NC \hskip.5cm\text{(Def. $Pr_{\geq p}$)}\NR
                            \NC \NC \equiv Pr (\{\pi \in Paths\ |\ \pi_0 \models True\}) \geq p 					\NC \hskip.5cm\text{(Sat. relation for AP)}\NR
                            \NC \NC \equiv Pr (\{\pi \in Paths\}) \geq p 											\NC \hskip.5cm\text{(Def. $\models True$)}\NR
                            \NC \NC \equiv 1 \geq p 																\NC \hskip.5cm\text{(Def. $Pr$)}\NR
                            \NC \NC \equiv True 																	\NC \hskip.5cm\text{($0\leq p\leq1$)}\NR
                        \stopalign\stopformula
                    
            \stopproof
                        
            \startexample
    	        For example, ORCON standards require ambulances to be on the 
    			incident scene within 14 minutes in 95\% of cases \cite[Sou93a]. This is 
    			captured by annotating the goal \goal{Achieve 
    			[AmbulanceOnSceneInTimeWhenIncident}Reported] with a RDS of 0.95.
            \stopexample
		
			\startdefinition{Probabilistic Goal}
				A goal G is \italic{probabilistic} if $0 < RDS (G) < 1$.
			\stopdefinition
			
			Given the estimated satisfaction rate $P(G)$ and the required degree
			of satisfaction $RDS(G)$ of a goal, we can measure the gap between 
			these estimated and prescribed probabilities. If $P(G) \geq RDS(G)$, 
			the goal's required satisfaction threshold is reached; 
			if $P(G) < RDS(G)$, it is not and this gap should be as low 
			as possible. The difference allows us to measure how severe 
			the goal violation is.
			
			\startdefinition{Violation Severity}
				The severity of violation of a goal G is defined by: 
				\startformula
					SV(G) = RDS(G) – P(G)
				\stopformula
			\stopdefinition
		        
        	The domain-consistency condition introduced in 
			\in{Section}[subsec:defining-goals]
			is generalized accordingly; it now states that there is a chance to observe 
			one behavior at least that satisfies the goal and the domain properties:
			 
			\startdefinition{Domain Consistent}
				A goal $G$ is consistent with the domain $Dom$ iff
    			\startformula
    				P (G\ |\ Dom) > 0
    			\stopformula
			\stopdefinition

			In our generalized setting for goals with a partial satisfaction rate, 
			we need to state what desirable goal refinements are. The completeness, 
			consistency and minimality conditions in \in{Section}[subsec:defining-goals]
			are generalized as follow:
			
			\startdefinition{Complete Refinement}
				A refinement of goal $G$ into subgoals $SG_1, ..., SG_n$
				is said to be complete iff
    			\startformula
					P (G\ |\ SG_1, ..., SG_n, Dom) = 1
    			\stopformula
			\stopdefinition
			
			Note that this condition could be relaxed to allow partial refinements.
			In a partial refinement, the satisfaction of the sub-goals does not
			guarantee that the satisfaction of the parent goal.
			
			A refinement of probabilistic goals is minimal if removing any subgoal
			from the refinement hinder its completeness.

			\startdefinition{Minimal Refinement}
				A refinement of goal $G$ into subgoals $SG_1, ..., SG_n$
				is said to be minimal iff
    			\startformula
					P (G\ | \bigwedge_{j\neq i} SG_j, Dom) < 1\hskip1cm \text{for all $i$ s.t. $1 \leq i \leq n$}
    			\stopformula
			\stopdefinition
			
			The definition of complete and minimal refinement could be relaxed
			to enable partial refinement. In the case of a partial refinement, the
			parent goal is not guarantee to be satisfied when the subgoals are satisfied.
			
			\startdefinition{Partial Refinement}
				A refinement of goal $G$ into subgoals $SG_1, ..., SG_n$
				is said to be partial iff
    			\startformula
					P (G\ |\ SG_1, ..., SG_n, Dom) < 1
    			\stopformula
			\stopdefinition
			
			\noindent A partial refinement is minimal if removing a subgoal from the
			refinement reduce the satisfaction rate of the parent goal.

			\startdefinition{Minimal Partial Refinement}
				A partial refinement of goal $G$ into subgoals $SG_1, ..., SG_n$
				is said to be minimal iff
    			\startformula
					P (G\ | \bigwedge_{j\neq i} SG_j, Dom) < P (G\ | \bigwedge_{j} SG_j, Dom)\hskip1cm \text{for all $i$ s.t. $1 \leq i \leq n$}
    			\stopformula
			\stopdefinition

			In a goal models, goals may be connected by \italic{conflict links} if
			the goals are conflicting. Goals are conflicting if there exists a non-trivial
			condition making them inconsistent with the domain

			\startdefinition{Conflicting goals}
				A set of goals $G_1, ..., G_n$ is conflicting if there exists a 
				boundary condition $B$ such that
    			\startformula
					P (G\ |\ B \wedge \bigwedge_{i} G_j, Dom) = 0 \hskip1cm P (B\ |\ Dom) > 0
    			\stopformula
			\stopdefinition


        \stopsubsection
        
        \startsubsection
        	[reference=ref:independence-goals,
			 title={Independence among Probabilistic Goals}]
        	
			\startcolor[red]
			The set of behaviors satisfying the goal \goal{Achieve [AmbulanceMobilizedWhenAllocated]}
			does not necessarily satisfy or deny the goal \goal{Achieve [AmbulanceAllocatedWhen IncidentReported]}
			in Fig. 1; whether an allocated ambulance is mobilized or not does not 
			depend on whether an ambulance is allocated or not. On the other hand, 
			the goals Achieve [AmbulanceMobilizedWhenAllocated] and Achieve [Allocated 
			AmbulanceMobilizedWhenOnRoad] are not independent; every behavior 
			satisfying the latter also satisfies the former. Goal dependence is 
			defined more precisely as follows.
			\stopcolor
			            
            Goal dependence in the example above is defined more 
    		precisely as follows:
            
            \startdefinition[dfn:goalindependance]{Goal Independence}
                Two goals are dependent if the set of behaviors that 
                satisfies one of them satisfies or denies the other. Two goals 
                are independent if they are not dependent. 
            \stopdefinition
            
            In terms of conditional probabilities, the independence of goals 
            $G_1$ and $G_2$ is characterized by the following conditions:
            
            \startformula \startalign [n=3,align={right,left,left}]
            	\NC P (G_1\ |\ G_2) \NC = P (G_1\ |\ \neg G_2) \NC = P (G_1), \NR
            	\NC P (G_2\ |\ G_1) \NC = P (G_2\ |\ \neg G_1) \NC = P (G_2). \NR
            \stopalign \stopformula
            
            In other words, two probabilistic goals are independent if their 
    		satisfaction rates do not change when the other goal is satisfied.
            
            
            The AND/OR refinement structure in a correct goal model can be 
    		exploited to syntactically determine whether two goals are independent.
            
            \startproposition
				In a goal graph whose AND-refinements are complete, two goals 
				are dependent if they are connected through a refinement path or a 
				conflict link.
            \stopproposition
            
           	\startproof
				(a) In a complete refinement, any behavior satisfying a child 
						goal is a behavior satisfying the parent goal (see the 
						entailment relation for complete refinements in 
						\in{Section}[sec:probabilistic-goal]). The independence of 
						the parent and child goals would, by definition, require at 
						least one behavior satisfying the child goal to not satisfy 
						the parent goal, which contradicts the completeness assumption.
						In view of the transitivity of entailments, the argument can 
						be recursively applied to ancestor goals.
				(b) If a goal $G_1$ conflicts with a goal $G_2$, we can find a 
						boundary condition $B$ such that 
						$P(G_2\ |\ G_1, B, Dom) = 0$ (see 
						the conflict relation in \in{Section}[sec:probabilistic-goal]).
						The set of 
						behaviors satisfying $G_1$ under such circumstances necessarily 
						denies $G_2$, and the goals are by definition dependent.
            \stopproof
            
            \startproposition
	            In a minimal, complete and consistent goal refinement, the subgoals 
	            are independent.
            \stopproposition
            
            \startproof
	            Assume a minimal, complete and consistent refinement of goal $G$
	            into two dependent subgoals $G_1$, $G_2$, with the set of 
	            behaviors satisfying $G_1$ (say) satisfying or denying $G_2$. 
	            If these behaviors satisfy $G_2$, we have: 
	            $P(G_2\ |\ G_1, Dom) = 1$. As the refinement is complete,
	            $P(G\ |\ G_1, G_2, Dom) = 1$. It reduces to
	            $P(G | G_2, Dom) = 1$; the refinement is thus not minimal which 
	            contradicts our assumption. If those behaviors deny $G_2$, 
	            a similar argument leads us to conclude that the refinement 
	            is not consistent as no behavior can be found that satisfies 
	            both subgoals. The extension to $n$ subgoals is straightforward.
        	\stopproof
        
        \stopsubsection
        
        \startsubsection
        	[reference=sec:patterns-probabilistic-goals,
	  		 title={Patterns for Probabilistic Goals}]
        
            Formalising probabilistic requirements is a tedious and error-prone task,
            although essential for formal and automated reasoning. 
            Specifications patterns encodes common formalisation to ease
            the specification of probabilistic goals. Refinement patterns encodes
            known tactics for decomposing goals into subgoals.
            We present here the probabilistic specification and refinement patterns 
            inspired from the specification patterns presented in \cite[Dar95a].
            
            \noindent\bold{Probabilistic Achieve/Cease}. An \italic{achieve} goal,
            \italic{cease} goal, 
            states that a target condition is true, false respectively,
            at some point in the future, when a 
            current condition is satisfied. The time elapsed between the states 
            satisfying the current and target conditions must be bounded to be
            finitely violable. In LTL, this is formalized as:
            
            \startformula
	            C \Rightarrow \lozenge_{\bowtie t} T \text{ (Achieve)}\text{\hskip1cm or \hskip1cm} C \Rightarrow \lozenge_{\bowtie t} \neg T \text{ (Cease)}
            \stopformula
            
            The probabilistic version of an achieve goal, cease goal, state that a target 
            condition is achieved, or not respectively, from a current condition, 
            with a probability above a 
            specified threshold. Such specification patterns is also sometimes referred 
            as Probabilistic Response \cite[Gru08a]. In PCTL*, this may be formalized 
            as:
            
            \startformula
	            C \Rightarrow_{\geq p} \lozenge_{\bowtie t} T \text{ (Achieve)}\text{\hskip1cm or \hskip1cm} C \Rightarrow_{\geq p} \lozenge_{\bowtie t} \neg T \text{ (Cease)}
            \stopformula
            
            
            \startexample
                For example, the goal \goal{Achieve [AmbulanceOnSceneWhenMobilized]} 
                stating that an ambulance shall be on incident scene within 10 minutes when 
                mobilized, can be formalized using the \italic{Achieve} specification 
                pattern. Using LTL, the goal might be formalized as follow:
                
                \startformula
                	\forall i: Incident, a: Ambulance \centerdot (Mobilized(a, i) \Rightarrow \lozenge_{\leq 10 min} OnScene (a, i))
                \stopformula
                
                Back to our example, if ambulance is expected to be on scene within 
                10 minutes only in 95\% of cases, the probabilistic achieve specification 
                pattern produces the following formalisation :
                
                \startformula\startalign[n=1, align={left}]
                    \NC \forall i: Incident, a: Ambulance \centerdot \NR
                    \NC \hskip 2em Mobilized(a, i) \Rightarrow_{\geq 95\%} \lozenge_{\leq 10 min} OnScene (a, i) \NR
                \stopalign\stopformula
                
                Formally, the PCTL assertion states that we are almost sure that in 
                every state reachable from the initial state, 95\% of the paths starting in 
                these states are such that a mobilized ambulance is on scene within 10 
                minutes.
             
            \stopexample
            
            \noindent\bold{Probabilistic Maintain}. A \italic{maintain} goal, 
            \italic{avoid} goal, states that a target condition is always true, 
            false respectively, given a condition on the current state. 
            The time for which the target condition is true may be bounded, or not.
            In LTL, this is formalized as:
            
            \startformula
	            C \Rightarrow \square_{\bowtie t} T \text{ (Maintain)}\text{\hskip1cm or \hskip1cm} C \Rightarrow \square_{\bowtie t} \neg T \text{ (Avoid)}
            \stopformula
            
            The probabilistic counterpart to maintain, avoid goal, states the target
            condition must hold for at least a given probability. This can be formalized as
            
            \startformula
	            C \Rightarrow_{\geq p} \square_{\bowtie t} T \text{ (Maintain)}\text{\hskip1cm or \hskip1cm} C \Rightarrow_{\geq p} \square_{\bowtie t} \neg T \text{ (Avoid)}
            \stopformula
            
            \startexample
            \stopexample
                        
        \stopsubsection
        
    \stopsection
    
    \startsection[title={Probabilistic Obstacles}]
    
    	\startsubsection[title={Defining and Modelling Probabilistic Obstacles}]
		\stopsubsection

    	\startsubsection[title={Independence among Probabilistic Obstacles}]
		\stopsubsection

    	\startsubsection[title={Patterns for Probabilistic Obstacles}]
		\stopsubsection
    
    \stopsection
    
\stopchapter

\stopcomponent