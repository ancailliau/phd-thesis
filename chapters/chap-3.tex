% !TEX root = thesis.tex

\startcomponent chap-3

\product thesis
\environment common

\startchapter
	[reference=chap:proba-framework,
   list={A Probabilistic Framework for Goal-Oriented Requirements Engineering},
   marking={A Probabilistic Framework for Goal-Oriented Requirements Engineering},
   bookmark={A Probabilistic Framework for Goal-Oriented Requirements Engineering},
	 title={\vbox{\hbox{A Probabilistic Framework for}\hbox{Goal-Oriented Requirements Engineering}}}]
    
    Many software failures originate from our tendency to conceive over-ideal
    software systems. Missing assumptions and unanticipated risks may lead to
    incomplete, innaccurate or inadequate requirements. Risk analysis helps the
    latter and should therefore be at the core of the requirements engineering
    process \cite[DeL95,DeL95b,Ant98,Lev02,Lam09]. Risk management is
    recognized to decrease the number of potential defects \cite[Jon08]. It
    aims at identifying, assessing and resolving risks preventing the
    software-to-be from fullfilling its intended mission. For the assessment
    step, risks might be assessed qualitatively or quantitatively. A common
    weakness comes from subjective estimates used in such assessment that might
    be innaccurate. Few requirement engineering frameworks support quantitative
    risk analysis and quantitative requirements as first class citizens; even
    fewer propose precise characterizations for quantitative risks.

    This chapter introduces probabilistic goals and obstacles. This precise
    characterization is intended to reduce subjective estimates. Formal
    foundations and definitions provide a basis for the techniques presented in
    the following chapters.

    The satisfaction rate of a goal or an obstacle is defined from the
    probability that system state satisfies the goal or obstacle's
    specification. The latter is defined as a measure over a probabilistic
    behavior model. The satisfaction rate of a goal is defined as the lowest
    state probability to satisfy the goal's specification whereas the
    satisfaction rate for an obstacle is defined as the highest state
    probability to satisfy the obstacle's specification. The refinement
    structure connecting non-probabilistic goals and obstacles is generalized
    to probabilistic goals; thereby the satisfaction arguments and the
    conditions imposed by the refinement structure are extended to the
    probabilistic framework. Specification patterns for probabilistic goals are
    also introduced to ease formal specification. As a result, the precise
    definitions for probabilistic goals and obstacles and the refinement
    structure connecting probabilistic goals and obstacles provides the basis
    for the quantitative obstacle assessment and control techniques in the next
    chapters.
        
    The chapter is organized as follows. \in{Section}[sec:formal-foundation]
    introduce the necessary formal background supporting the definitions
    presented in the following sections. \in{Section}[sec:probabilistic-goals]
    introduces a precise definition for probabilistic goals and shows how
    probabilistic goals relate to each other in a generalized refinement
    structure. \in{Section}[sec:probabilistic-obstacles] defines probabilistic
    obstacles and shows how probabilistic obstacles relate to each other and
    how they connect to probabilistic goals.
    \in{Section}[sec:formal-spec-probabilistic] shows how probabilistic goals
    and obstacles are formally specified.

    \startsection
     	[reference=sec:formal-foundation, 
       title={Formal Background}]
       
      The satisfaction rate of a probabilistic assertion depends on the
      probability that a system state satisfy this assertion, as introduced in
      \in{Section}[sec:probabilistic-goals]. Intuitively, this state
      probability corresponds to the ratio between the number of behaviors
      satisfying the assertion over the number of possible behaviors.
      
      As the number of such behaviors might be infinite, a ratio between
      numbers of behaviors is not well defined. A proper definition requires
      measurability for such sets of behaviors. This requires the notions of
      $\sigma$-algebra and probability spaces, introduced in
      \in{Section}[sec:sigma-algebra]. To support practical ways for computing
      satisfaction probabilities, \in{Section}[sec:probabilistic-behavior]
      introduces Markov chains as a probabilistic behavioral model.
      \in{Section}[sec:pctl] then introduces the PCTL and PCTL* logics for
      specifying probabilistic assertions.
	     
      The reader familiar with $\sigma$-algebras, probability spaces,
      Markov-chains and PCTL/PCTL* logic may skip this section. The background
      recalled here is largely inspired from \cite[Bai08] where details and
      proofs can be found.
      
      \startsubsection
        [reference=sec:sigma-algebra,
         title={$\sigma$-Algebras and probability spaces}]
  
        Informally, the probability that an assertion about system behaviors is
        satisfied is defined as the ratio between the number of behaviors
        satisfying the assertions over all possible behaviors. For example, the
        probability of \quote{\it {Every 30 minutes, the water level shall be
        25 cm above the LOW limit}} will be determined by the ratio between the
        number of possible behaviors where the water level is above the LOW
        limit over the number of all possible behaviors. Assuming that 6
        behaviors satisfy the assertion over 10 possible behaviors, the
        probability for the assertion would be $.6$. However, such ratio is not
        well defined as the number of possible behaviors might be infinite. To
        provide a correct definition, the set of behaviors must be measurable.
        
        \startdefinition{Measurable set}
        
        A set is measurable if a corresponding $\sigma$-algebra
        exists; a probability measure over that $\sigma$-algebra then
        quantifies the probability of satisfying an assertion.
       
        \stopdefinition
       
        \startdefinition{$\sigma$-algebra}
       
          A $\sigma$-algebra over a set of behaviors $\{\pi_0, \pi_1, ...\}$ is
          a collection $\Sigma$ of subsets of behaviors $\Sigma = \{B_0, B_1,
          B_2, ...\}$ such that:
			
          \startitemize[packed]
      
            \item The collection contains the empty set 
            \startformula
              \emptyset \in \Sigma
            \stopformula
             
            \item The collection is closed under complementation, that is,
            \startformula
              \text{if }B_i \in \Sigma\text{, then }(\Sigma \textbackslash B_i) \in \Sigma
            \stopformula
	         
            \item The collection is closed under countable union, that is,
            \startformula
              \text{if }B_0, B_1, B_2, ... \in \Sigma\text{, then }(B_0 \cup B_1 \cup B_2 \cup ...) \in \Sigma
            \stopformula
         
          \stopitemize
        
        \stopdefinition
         
        In the following, we use $\pi$ to denote a behavior and $B$ to denotes
        a set of behaviors. For example, consider the set of possible behaviors
        $\{\pi_0, \pi_1\}$. The following collection $\Sigma$ forms a
        $\sigma$-algebra for $\{\pi_0, \pi_1\}$:
         
        \startformula
          \Sigma = \{\emptyset, \{\pi_0\}, \{\pi_1\}, \{\pi_0, \pi_1\}\}
        \stopformula
         
        It contains the empty set, is closed under complementation and is
        closed under countable union.
           
        The powerset $2^B$ generates a $\sigma$-algebra over $B$. In the
        thesis, we always consider the $\sigma$-algebra to be generated by the
        powerset $2^B$.
           
        The $\sigma$-algebra $\Sigma$ is equipped with a function that maps the
        subsets to a real number between $0$ and $1$, capturing the 
        relative size of behavior subsets with respect to the set of all possible behaviors.
        It provides a
        probability to each element of the $\sigma$-algebra.
        
        \startdefinition{Probability measure}
        
        A \italic{probability measure} for a $\sigma$-algebra $\Sigma = \{B_0,
        B_1, ...\}$ is a function mapping subsets $B_0, B_1, ...$ to a real
        number between $0$ and $1$, such that:
       
        \startitemize[packed]
         
        	\item The probability of the subset containing all the behaviors is
        	$1$, that is,
	       
          \startformula
      	    Pr(B) = 1
	        \stopformula
         
          \item If $B_i$ and $B_j$ are subsets that do not share a behavior
          (that is $B_i \cap B_j = \emptyset$), their probability is obtained
          by summing the probability of the subsets:
	       
          \startformula
      	    Pr(B_i \cup B_j) = Pr(B_i) + Pr(B_j)
	        \stopformula
         
        \stopitemize
        
        \stopdefinition
         
        Assume that we want to obtain the probability of observing the single
        behavior $\{\pi_0\}$. We might define the following probability measure
        function $Pr$, over the generated $\sigma$-algebra $\Sigma$ provided
        above:
         
	      \startformula \startalign [n=4,align={right,left}]
    	    \NC Pr(\emptyset) 	 \NC = 0, \hskip2cm \NC Pr(\{\pi_0\}) \NC = .4, \NR
          \NC Pr(\{\pi_0,\pi_1\})) \NC = 1,           \NC Pr(\{\pi_1\}) \NC = .6, \NR
	      \stopalign \stopformula

        In this case, the probability to observe $\{\pi_0\}$ over all possible
        behaviors is $.4$.

        As a result, the informal ratio over behaviours is now more precise and
        well defined. This, however, is not practical as it requires the
        probability for each subset of the possible behaviors to be specified.
        In addition, it requires all the behaviors satisfying an assertion to
        be enumerated. These limitations are raised in the following
        subsections.

		  \stopsubsection
		
      \startsubsection
			  [reference=sec:probabilistic-behavior,
			   title={Probabilistic behavior models and measurable statements}]
            
        The characterisation of the probability of satisfaction of an assertion
        presented in the previous section requires a probability measure
        function for all possible combinations of behaviors. Hopefully, if the
        behaviors of the system can be described by a probabilistic behavior
        model (such as a Markov chain), a $\sigma$-algebra and probability
        measure are provided. A Markov chain no longer requires a probability
        measure function to be provided for all combinations. This makes our
        characterization usable in practical applications.
                    
        A {\it Markov Chain} is a state machine where transitions between
        states are decorated by probabilities. The successor of a state is
        chosen according to probabilities on the outgoing transitions. The
        probability of a transition only depends on the source and the target
        node. It does not depend on the history for reaching the source node.
        This is also known as \italic{memoryless} property.
        
        \startdefinition{Markov Chain}
        
        A {\it Markov Chain} is a tuple $(S, \mathcal{P}(s,s'),
        Init,$ $AP, L)$ where
        
        \startitemize
        
          \item $S$ is a set of states,

          \item $\mathcal{P}(s,s')$ specifies the probability to move from a
          state $s$ to a state $s'$ in a simple step,

          \item $Init$ specifies the possible initial states, with their
          respective probabilities,

          \item $AP$ is a set of atomic propositions,

          \item $L$ is labelling function mapping states to a set of atomic
          propositions.
        
        \stopitemize
        
        \stopdefinition
        
        A Markov Chain is often depicted by a graph where states are nodes
        and transitions are edges. Edges are annotated with the corresponding
        probability. Probabilities $1$ on edges are omitted.
        \in{Figure}[fig:water_pump_system] shows a Markov chain corresponding
        to a simple system controlling a pump with 2 states:
        {\it WaterPumpOn} and {\it WaterPumpOff}.
            
        \placefigure[here]
        	[fig:water_pump_system]
        	{A simple pump control system}
        	{\externalfigure[../images/chap3/water_pump_system.pdf]}
        
        For a given Markov chain, we are interested in the corresponding
        probability measure function. This probability measure is defined over
        the $\sigma$-algebra generated from the cylinder sets for the possible
        behaviors. The set of possible behaviors $B$ described by the Markov
        chain is the set of infinite sequence of states $s_0s_1s_2s_3...$ such
        that $\mathcal{P}(s_i,s_{i+1}) > 0$. Given a prefix, the cylinder set
        is the set containing all the behaviors that share the prefix.
        Formally, a cylinder set spanned by a finite behavior $\hat\pi$ is the
        set of infinite behaviors with the prefix $\hat\pi$:
        
        \startformula
          Cyl(\hat\pi) = \{\pi \in B\mid \hat\pi \in pref(\pi)\}
        \stopformula
        
        where $pref(\pi)$ denotes all the prefixes for the behavior $\pi$.
        
        Using the Markov chain in \in{Figure}[fig:water_pump_system], the
        cylinder set for {\ss (Water\-Pump\-On, Water\-Pump\-Off)} contains the
        behaviors {\ss (Water\-Pump\-On, Water\-Pump\-Off, Water\-Pump\-On,
        Water\-Pump\-Off,...)} and {\ss (Water\-Pump\-On, Water\-Pump\-Off,
        Water\-Pump\-On, Water\-Pump\-On, ...)} but not {\ss (Water\-Pump\-On,
        Water\-Pump\-On, Water\-Pump\-Off,...)}.
        
        The $\sigma$-algebra associated with the Markov chain is the smallest
        $\sigma$-algebra that contains all the cylinder sets spanned by all
        finite behavior fragments from the Markov Chain. The probability
        measure associated with this $\sigma$-algebra enables a practical
        computation of the probability of a cylinder set:
        
        \startformula
        	Pr(Cyl(s_0...s_n)) = Init(s_0)\times\prod_{0\leq i<n}\mathcal{P}(s_i, s_{i+1})
        \stopformula
        
        For our example, the probability for the cylinder set for {\ss
        (Water\-Pump\-On, Water\-Pump\-Off)} will be given by
        
        \startformula
        	Pr(Cyl({\ss WaterPumpOn,WaterPumpOff})) = 1\times.99
        \stopformula
        
        This characterization provides a pratical way of determining the
        probability of observing a set of behaviors described by a cylinder.
        However, this leaves us with the problem of enumerating the behaviors (or
        the cylinder sets) corresponding to an assertion.
        
        Hopefully, the cylinders can be generated from an LTL assertion. For
        example, the assertion {\ss{\bf sooner-or-later} GC} generates the
        cylinder sets $Cycl(s_0...s_i)$ where $s_i\vDash GC$. The probability
        is then given by $\sum_iP(Cycl(s_0...s_i))$. It is possible to
        analytically compute the value resulting from the infinite sum.
        However, efficient algorithms exist for computing the probability that
        behaviors starting from a state $s$ satisfy an LTL assertion.
        \cite[Bai08] provides more details about the measurability of the set
        of behaviors and dedicated algorithms. In the thesis, we use the
        following notation for the probability that behaviors starting in $s$
        satisfy the assertion $\phi$:
        
        \startformula
          Pr^s(\phi) = Pr (\{\pi \in Behaviors(s)\mid \pi \vDash \phi \})
        \stopformula
        
        \noindent where $\phi$ is an LTL expression and $Behaviors(s)$ refers to
        the set of possible behaviors starting in $s$.
        
        This section introduced the formal semantic that will be used for
        probabilistic goals and obstacles in the next section. The probability
        measure is defined over a Markov chain that must not necessarily be
        explicitely specified; we assume that such Markov chain exists and
        captures the behaviors exhibited by the system.
        
      \stopsubsection
    
    	\startsubsection
  		  [reference=sec:pctl,
         title={The PCTL and PCTL* formalisms}]
         
        The previous sections introduced a precise definition enabling the
        computation of the probability of an LTL-like assertion. This section
        introduces formal logics enabling the specification of constraints on
        the probability of satisfying LTL-like assertions. As
        \in{Section}[sec:formal-spec-probabilistic] will show, these logics can
        be used to formally specify probabilistic goals and obstacles.
        
        PCTL and PCTL* are based on CTL. CTL differs from LTL as CTL is
        interpreted over states and not over behaviors. In a CTL formula,
        behaviors are universally quantified\emdash{}i.e., all behaviors
        starting from the state satisfy the formula\emdash{}or existentially
        quantified\emdash{}i.e., there is a behavior starting from the state
        that satisfies the formula. PCTL formulas can be seen as quantitative
        counterpart of CTL where behaviors are quantified according to their
        probability.
        
        PCTL {\it state formulas} are built using standard logic connectives
        (such as $\wedge$, $\vee$, $\neg$, $\rightarrow$, $\leftrightarrow$)
        over atomic propositions. A state formula can include the probability
        operator ${\blackboard{}P}_I(\psi)$ where $\psi$ is a behavior formula, and
        $I \subseteq [0,1]$ is a non-empty interval. The behavior formulas
        are built using the temporal operators (such as $\ltlF$, $\ltlG$,
        $\ltlW$, $\ltlU$) over state formulas. Boolean combinations of behavior
        formulas are not allowed in PCTL, but are allowed in PCTL*. PCTL* is
        strictly more expressive than PCTL. All formulas expressed in LTL can
        be expressed in PCTL* but not in PCTL \cite[Bai08].
        
        For convenience, intervals for the probabilistic operators are often
        abbreviated, e.g. ${\blackboard{}P}_{\geq .5}(\psi)$ denotes
        ${\blackboard{}P}_{[.5,1]}(\psi)$; ${\blackboard{}P}_1(\psi)$ denotes
        ${\blackboard{}P}_{[1,1]}(\psi)$; etc.
        
        The duality between the $\ltlF$- and $\ltlG$-operators relates their
        respective lower and upper bound:
    
        \startformula
        	{\blackboard{}P}_{\leq p}(\ltlF\phi) = {\blackboard{}P}_{> 1-p}(\ltlG\neg\phi)
        \stopformula
    
        More generaly, we have:
    
        \startformula
  	      {\blackboard{}P}_{\leq p}(\psi) = \neg{\blackboard{}P}_{> 1 - p}(\psi)
        \stopformula
        
        In our framework, PCTL formulas are interpreted over states and
        behaviors of a Markov chain. The set of behaviors specified by a PCTL
        or a PCTL* formula is also measurable (see \cite[Bai08] for a proof);
        we can then compute the probability of satisfying a probabilistic
        assertion. \in{Section}[sec:formal-spec-probabilistic] will show how
        probabilistic goals and obstacles are formally specified using PCTL and
        PCTL*.
    
      \stopsubsection
    
    \stopsection
    
    \startsection
    	[reference=sec:probabilistic-goals,
		   title={Probabilistic Goals}]
       
      Probabilistic requirements, such as \quote{\it the water level shall be
      above the LOW limit in 95\% of the cases}, often arise from standards,
      regulations or guidelines. Few model-driven RE frameworks to date handle
      these as first-class citizens. As goals are partially satisfied due to
      obstacles, it seems important that such probabilistic statements are
      handled in the same framework.
      
      \in{Section}[sec:defining-probabilistic-goals] provides a formal
      definition for probabilistic goals based on the formal background
      presented in previous section.
      \in{Section}[sec:modeling_probabilistic_goals] generalizes for
      probabilistic goals the notion of refinement structure relating
      non-probabilistic goals to each other.
      \in{Section}[ref:independence-goals] discusses the independence of goals.
      
    	\startsubsection
			[reference=sec:defining-probabilistic-goals,
			 title={Defining probabilistic goals}]
   
        An {\it Achieve} goal $\ltlG (C \rightarrow \ltlF T)$ requires
        behaviors where all possible system states satisfy $C\rightarrow\ltlF
        T$. As the goal might be satisfied only partially, a state $s$ has a
        probability that the behaviors starting from it satisfy
        $C\rightarrow\ltlF T$.

        \startdefinition{State probability}
        
          The {\it state probability} of a non-probabilistic formula $\phi$ in
          state $s$, denoted by $P^s(\phi)$, is defined as the value of the
          probability measure $Pr^s(\phi)$ over the underlying Markov chain.
          
        \stopdefinition
        
        The state probability $P^s(\phi)$ intuitively corresponds to the ratio
        between {\it (a)} the number of possible behaviors rooted on $s$
        satisfying $\phi$, and {\it (b)} the number of possible behaviors
        rooted on $s$.
        
        \startdefinition{Goal satisfaction rate}

          The {\it satisfaction rate of a goal} of form $\ltlG (P \rightarrow
          \Theta Q)$ is the lowest state probability $P^s(P \rightarrow \Theta
          Q)$ for any possible state $s$.
        
        \stopdefinition
        
        We take a conservative approach here, and require a {\it lower} bound
        as we need to pessimistically consider the lowest chance of goal
        satisfaction. In the following, $P(G)$ denotes the satisfaction rate of
        a goal $G$; thus, for a goal $P \rightarrow \Theta Q$:
        
        \startformula
				  P(G) = \min_{s \in S}P^s(P \rightarrow \Theta Q)
			  \stopformula
        
        where $S$ is the set of possible states. A goal is {\it fully satisfied} 
        if its satisfaction rate is equal to 1. 
        
        For example, consider a system with three states and the goal
        \goal{Achieve [Alarm Raised When Low Water]}, specified by the assertion
   
        \startformula
          WaterLevel \leq LOW \Rightarrow \ltlF_{< 5 \text{min}} AlarmRaised
        \stopformula

        Assume that this assertion has a state probability $.1$ in $s_1$; $.2$
        in $s_2$; and $.3$ in $s_3$. Its satisfaction rate is its lowest state
        probability, that is, $.1$. The system satisfies

        \startformula
          \ltlG \left[\mathbb{P}_{\geq .1} (WaterLevel \leq LOW \Rightarrow \ltlF_{< 5 \text{min}} AlarmRaised)\right]
        \stopformula
        
        The same applies to a {\it Maintain} goal of form $C \Rightarrow G$;
        with satisfaction rate $x$; It prescribes that all system states
        satisfy the assertion $C\rightarrow G$ with at least a probability $x$.
        
        \startformula
				  P(C\Rightarrow G) = \min_{s \in S}P^s(C\rightarrow G)
			  \stopformula
        
        However, such formulation causes the satisfation rate of a {\it
        Maintain} goal to often equal $0$. Indeed, only one state satisfying
        $C\wedge\neg{}G$ is sufficient for this. In practice, the formulation
        is often too strong and needs to be relaxed. For example, the goal
        $\ltlG(C\rightarrow G)$ might be relaxed to $\ltlG(C \rightarrow
        \ltlG_{\geq t} G)$. Back to our example, the goal \goal{Maintain [Water
        Level Above LOW]} might be formalized as
        
        \startformula
          \ltlG (WaterLevel > LOW)
        \stopformula  
          
        Such formulation is however not realistic; it is likely to have a
        satisfaction rate of $0$. A more realistic formalization would be
        
        \startformula
          \ltlG\,\ltlG_{\geq 30\,min}(WaterLevel > LOW)
        \stopformula  
        
        This deidealized goal states that the water level is above {\ss LOW}
        for at least 30 minutes. States are more likely to satisfy this
        assumption partially.
        
        We are sometimes interested in {\it conditional satisfaction rate},
        considering the satisfaction rate of a goal to be satisfied given that
        some properties hold. Recalling the definition of $P^s(P \Rightarrow
        \Theta Q)$ from \in{Section}[sec:probabilistic-behavior], for a goal
        $G$ formalized as $P \Rightarrow \Theta Q$, we have
        
        \startformula
				  P(G) = \min_{s \in S}P^s(\phi) = \min_{s \in S}P^s(\{\pi \in \,\graymath{Behaviors(s)}\,\mid \pi \vDash P \rightarrow \Theta Q\})
			  \stopformula
        
        The set of $Behaviors(s)$ might be restricted to a subset of behaviors
        satisfying some property $H$. 
        
        \startdefinition{Conditional goal satisfaction rate}
        
          The {\it conditional satisfaction rate} for a goal $G$ and a property
          $H$, denoted $P(G\mid{}H)$, is the satisfaction rate of $G$ over the
          behaviors satisfying the property $H$. For a goal $G$ of form $P
          \rightarrow \Theta Q$, that is,
      
  			  \startformula
  				  P(G\mid{}H) = \min_{s \in S}P^s(\{\pi \in \,\graymath{\{\pi' \in Behaviors(s)\mid \pi' \vDash H \}}\,\mid \pi \vDash P \rightarrow \Theta Q\})
  			  \stopformula
        
        \stopdefinition
            
        The definitions above provide the basis for probabilistic goals. The
        latter are annotated with an {\it estimated} satisfaction rate and a
        {\it required} satisfaction rate.
            
        \startdefinition[dfn:esr]{Estimated goal satisfaction rate}
        
          The {\it estimated satisfaction rate} (ESR) of a goal is the
          satisfaction rate of this goal in view of its possible obstructions.

        \stopdefinition
          
        The ESR is computed from the goal/obstacle models;
        \in{Chapter}[chap:assessing] will describe how estimated satisfaction
        rates for high-level goals are computed from the estimated satisfaction
        rate of obstacles.
                  
        In our running example, the water level might not be within the
        tolerable limits for various reasons, e.g., a leak in the pool, some
        evaporation, an unnecessary refill, a dysfunctional water pump, etc.
        Due to such obstacles, there is a chance of this goal not being fully
        satisfied. Its ESR is likely to be lower than $1$.
            
        \startdefinition[dfn:rds]{Required satisfaction rate}
    	  
          The r{\it equired satisfaction rate}\footnote{Previous papers
          \cite[Cai12,Cai13,Cai14,Cai15] refers to the required
          satisfaction rate as {\it required degree of satisfaction}.
          Terminology was changed to avoid confusion with degree of
          satisfaction in fuzzy logic frameworks.} (RSR) of a goal is the
          minimal satisfaction rate admissible for this goal. It is imposed by
          elicited requirements, existing regulations, standards, and the like.
        
        \stopdefinition
        
        The ESR shall be ideally above the RSR. Analysts might introduce
        a {\it Tolerable Satisfaction Rate} (TSR) above the required
        satisfaction rate to capture a buffer zone between required and
        desirable statisfaction rates. With such buffer zone, the ESR must be
        above the RSR and shall ideally be above the TSR. 
                          
        For example, we might require that the temperature of our spent fuel
        pool does not exceed 54°C for more than 20 minutes in 95\% of cases.
        This is captured by annotating the goal
        \goal{Maintain [Water Temperature Below 54]} with a RSR of $.95$.
		
		    \startdefinition{Probabilistic goal}
				
          A goal G is \italic{probabilistic} if 
          \startformula
            0 \leq RSR (G) \leq 1
          \stopformula
        
        \stopdefinition
        
        Note that non-probabilistic goals are generalized here; for such goals
        we have: $RSR (G) = 1$.
		       
        Given the estimated satisfaction rate $P(G)$ and the required
        satisfaction rate $RSR(G)$ of a goal, we can measure the gap between
        these satisfaction rates. If $P(G) \geq RSR(G)$, the goal's required
        satisfaction threshold is reached; if $P(G) < RSR(G)$, it is not; the
        gap should then be as low as possible. The difference, called violation
        severity, allows us to measure how severe the goal violation is.
        \in{Figure}[fig:sv] shows how RSR and ESR relate.
			
        \startdefinition[dfn:vs]{Violation severity}
				
          The severity of violation of a goal $G$ is defined by: 
          
          \startformula
					  SV(G) = RSR(G) - P(G)
          \stopformula

        \stopdefinition
            
        \placefigure[here]
        	[fig:sv]
        	{Violation Severity (SV) measures the gap between the Required
        	Satisfation Rate (RSR) and the Estimated Satisfaction Rate (ESR).}
        	{\startMPcode
            rsr := .95;
            esr := .7;
            
            scale := 10cm;
            rsr_s := rsr * scale;
            esr_s := esr * scale;
            
        	  fill unitsquare xscaled (rsr_s-esr_s) yscaled .3cm xshifted esr_s withcolor red;
        	  draw unitsquare xscaled scale yscaled .3cm withcolor black;
            
        	  label.top(btex $SV = .25$ etex scaled .75, ((rsr_s-esr_s)/2+esr_s,.5cm));   
            draw (esr_s,.4cm) -- (rsr_s,.4cm) withcolor black;
            draw (esr_s,.35cm) -- (esr_s,.45cm) withcolor black;
            draw (rsr_s,.35cm) -- (rsr_s,.45cm) withcolor black;
            
            draw (0cm,0cm) -- (0cm,.5cm) withcolor black;
        	  label.top(btex $0$ etex scaled .75, (0cm,.5cm));
            
            draw (scale,0cm) -- (scale,.5cm) withcolor black;
        	  label.top(btex $1$ etex scaled .75, (scale,.5cm));
             
            draw (esr_s,.3cm) -- (esr_s,-.2cm) withcolor black;
        	  label.llft(btex $ESR = .7$ etex scaled .75, (esr_s,-.2cm));
            
            draw (rsr_s,.3cm) -- (rsr_s,-.2cm) withcolor black;            
        	  label.llft(btex $RSR = .95$ etex scaled .75, (rsr_s,-.2cm));
        	\stopMPcode}
        
        Similarily to non-probabilistic goals, a probabilistic goal shall be consistent
        with its domain. The domain-consistency condition introduced in
        \in{Section}[sec:background_goal] is generalized accordingly; it
        states that there is a least one behavior that satisfies both the goal
        and the domain properties:
			 
        \startdefinition{Domain consistency}
				
          A goal $G$ is consistent with the domain $Dom$ iff
    			
          \startformula
    				P (G\mid Dom) > 0
    			\stopformula
          
        \stopdefinition
        
      \stopsubsection
      
    	\startsubsection
			[reference=sec:modeling_probabilistic_goals,
			 title={Probabilistic goal models}]
       
        In a goal model, goals are connected to other goals through refinement
        links. Refinements are generalized here to probabilistic goal
        satisfaction. The completeness, consistency and minimality conditions
        in \in{Section}[sec:background_goal] are generalized as follows.
        
        A refinement of probabilistic goals is {\it complete} if the
        satisfaction of the subgoals is sufficient for the satisfaction of the
        parent goal.
			
        \startdefinition{Complete refinement}
			
          A refinement of goal $G$ into subgoals $SG_1, ..., SG_n$ is said to
          be complete iff
  			
          \startformula
					  P (G\mid SG_1, ..., SG_n, Dom) = 1
    			\stopformula

        \stopdefinition
		
			  A refinement of probabilistic goals is {\it consistent} if at
			  least one behavior satisfies all subgoals and domain properties.

			  \startdefinition{Consistent refinement}
			
          A refinement of a goal $G$ into subgoals $SG_1, ..., SG_n$ is said to
          be consistent iff
  			
          \startformula
					  P (SG_1, ..., SG_n, Dom) > 0
    			\stopformula

        \stopdefinition
		
			  A refinement of probabilistic goals is {\it minimal} if
			  removing any subgoal from the refinement hinder its completeness.

			  \startdefinition{Minimal refinement}
			
          A refinement of a goal $G$ into subgoals $SG_1, ..., SG_n$ is said to
          be minimal iff
  			
          \startformula
					  P (G\ \mid \bigwedge_{j\neq i} SG_j, Dom) < 1\hskip1cm \text{for all $i$ s.t. $1 \leq i \leq n$}
    			\stopformula

        \stopdefinition
        
        A refinement of probabilistic goals is said to be {\it correct} if it
        satisfies the completeness, consistency and minimality conditions.
        
        \startdefinition{Correct refinement}

          A {\it correct refinement} is complete, consistent and minimal.
        
        \stopdefinition
			
			  The completeness condition could be relaxed to allow for partial
			  refinements. In a partial refinement, the satisfaction of the subgoals
			  does not fully guarantee the satisfaction of the parent goal.
			
			  \startdefinition{Partial refinement}
				  
          A refinement of a goal $G$ into subgoals $SG_1, ..., SG_n$ is said to
          be partial iff
    			
          \startformula
					  0 < P (G\mid SG_1, ..., SG_n, Dom) < 1
    			\stopformula
          
        \stopdefinition
			
			  \noindent A partial refinement is minimal if removing a subgoal from
			  the refinement reduces the satisfaction rate of the parent goal. In other
			  words, a partial refinement is minimal if each goal contributes to the
			  probabilistic satisfaction of the parent goal.

			  \startdefinition{Minimal partial refinement}
				
          A partial refinement of goal $G$ into subgoals $SG_1, ..., SG_n$ is
          said to be minimal iff
    			
          \startformula
					  P (G\ \mid \bigwedge_{j\neq i} SG_j, Dom) < P (G\ \mid \bigwedge_{j} SG_j, Dom)\hskip1cm \text{for all $i$ s.t. $1 \leq i \leq n$}
    			\stopformula
          
			  \stopdefinition

        In a goal model, goals are connected by \italic{conflict links} if the
        goals are conflicting, as recalled in \in{Section}[sec:goal_conflict].
        Goals are conflicting if there exists a non-trivial boundary condition
        making them inconsistent within the domain. In our probabilistic
        framework, goals are conflicting if there exist at least one behavior
        satisfying the boundary condition that prevents the satisfaction of the
        parent goal.

			  \startdefinition{Conflicting goals}
      
				  A set of goals $G_1, ..., G_n$ is conflicting if there exists a
				  boundary condition $B$ such that
        
    			\startformula
				    P (G_i\mid B \wedge \bigwedge_{i} G_{i\neq j}, Dom) = 0,\hskip1cm P (B\mid Dom) > 0
    			\stopformula

        \stopdefinition
        
        \noindent As expressed by the second condition, the boundary condition
        $B\wedge Dom$ must be realizable by the environment.

      \stopsubsection
        
      \startsubsection
        [reference=ref:independence-goals,
         title={Independence among probabilistic goals}]
        	
        In our example, the set of behaviors satisfying the goal \goal{Maintain
        [Water Level Above LOW]} does not necessarily satisfy or deny the goal
        \goal{Achieve [Alarm Raised When Fire Detected]}. Whether the level of
        the water is above the {\ss LOW} limit does not depend on whether the
        software raises an alarm when a fire is detected. On the other hand,
        the goals \goal{Achieve [Make Up Water Provided When Requested]} and
        \goal{Achieve [Valve Opened When Water Requested]} are not independent
        from each other; every behavior satisfying the latter also satisfies
        the former. Goal dependence is defined more precisely as follows.
            
        \startdefinition[dfn:goalindependence]{Goal weak independence}
        
          Two goals are {\it weakly dependent} if the set of behaviors that
          satisfies one of them satisfies or denies the other. Two goals are
          {\it weakly independent} if they are not weakly dependent.
        
        \stopdefinition
        
        \noindent In terms of probabilities, $G_1$ depends on $G_2$ iff
        
        \startformula
          P (G_1\mid G_2) = 0\hskip1cm\text{ or }\hskip1cm P (G_1\mid G_2) = 1
        \stopformula
            
        This condition might however be stronger. 
        
        \startdefinition{Goal strong independence}
        
          Two goals are {\it stronly dependent} if the set of behaviors that
          satisfies one of them impacts the satisfaction or falsification of
          the other. Two goals are {\it strongly independent} if they are not
          strongly dependent.
        
        \stopdefinition
        
        \noindent In terms of conditional probabilities, the {\it strong
        independence} of goals $G_1$ and $G_2$ is characterized by the
        following conditions:
            
        \startformula \startalign [n=3,align={right,left,left}]
          \NC P (G_1\mid G_2) \NC = P (G_1\mid \neg G_2) \NC = P (G_1), \NR
          \NC P (G_2\mid G_1) \NC = P (G_2\mid \neg G_1) \NC = P (G_2). \NR
        \stopalign \stopformula
            
        In other words, two probabilistic goals are {\it strongly independent}
        if their satisfaction rates do not change when the other goal is
        satisfied. This is, however, a difficult condition to guarantee.
        For example, the goals \goal{Achieve [Valve Opened When Water
        Requested]} and \goal{Achieve [Make Up Pump Motor On When Water
        Requested]} share the obstacle \obstacle{No Power Available}. If
        \goal{Achieve [Valve Opened When Water Requested]} is satisfied, the
        obstacle \obstacle{No Power Available} is not. Therefore, given that
        $G$ is \goal{Achieve [Make Up Pump Motor On When Water Requested]}, we
        have

        \startformula
          P(G\mid\neg\obstacle{No Power Available}) > P(G)
        \stopformula
        
        These two goals are not {\it strongly} independent but are {\it weakly}
        independent; the satisfaction of \goal{Achieve [Valve Opened When Water
        Requested]} does not entail nor prevent the satisfaction of
        \goal{Achieve [Make Up Pump Motor On When Water Requested]}.
        
        The AND/OR refinement structure in a correct goal model can be
        exploited to syntactically determine whether two goals are independent.
            
        \startproposition
				  
          In a probabilistic goal graph whose AND-refinements are complete, two
          goals are weakly dependent if they are connected through a refinement.
        
        \stopproposition
            
       	\startproof In a complete refinement, any behavior satisfying a child
       	goal is a behavior satisfying the parent goal (see the entailment
       	relation for complete refinements in
       	\in{Section}[sec:modeling_probabilistic_goals]). The independence of
       	the parent and child goals would, by definition, require at least one
       	behavior satisfying the child goal to not satisfy the parent goal,
       	which contradicts the completeness assumption. In view of the
       	transitivity of entailments, the argument can be recursively applied to
       	ancestor goals. \stopproof

        \startproposition
				  
          Two goals are weakly dependent if they are connected through a
          conflict link.
        
        \stopproposition

       	\startproof If a goal $G_1$ conflicts with a goal $G_2$, we can find a
       	boundary condition $B$ such that $P(G_2\mid G_1, B, Dom) = 0$ (see the
       	conflict relation in \in{Section}[sec:modeling_probabilistic_goals]).
       	The set of behaviors satisfying $G_1$ under such circumstances
       	necessarily denies $G_2$, and the goals are by definition dependent.
       	\stopproof
            
        \startproposition
	      
          In a minimal, complete and consistent probabilistic goal refinement,
          the subgoals are weakly independent.
        
        \stopproposition
            
        \startproof Assume a minimal, complete and consistent refinement of
        goal $G$ into two dependent subgoals $G_1$, $G_2$, with the set of
        behaviors satisfying $G_1$ satisfying or denying $G_2$. If these
        behaviors satisfy $G_2$, we have $P(G_2\mid G_1, Dom) = 1$. As the
        refinement is complete, $P(G\mid G_1, G_2, Dom) = 1$. It reduces to
        $P(G \mid G_2, Dom) = 1$; the refinement is thus not minimal which
        contradicts our assumption. If those behaviors deny $G_2$, a similar
        argument leads us to conclude that the refinement is not consistent as
        no behavior can be found that satisfies both subgoals. The extension to
        $n$ subgoals is straightforward. \stopproof
        
      \stopsubsection
        
    \stopsection
    
    \startsection
      [reference=sec:probabilistic-obstacles,
       title={Probabilistic Obstacles}]
      
      Requirements may be only partially satisfied due to the adverse
      conditions preventing their satisfaction. In our probabilistic framework,
      the satisfaction rate of a goal depends on the satisfaction rate of the
      obstacles preventing its satisfaction.
      
      The section defines probabilistic obstacles
      (\in{Section}[sec:defining_obstacles]) and generalizes the conditions
      presented in \in{Section}[sec:background_obstacle] that relate obstacles
      to goals and obstacles to each other
      (\in{Section}[sec:modeling_probabilistic_obstacles]).
      \in{Section}[ref:independence-obstacles] then discusses conditions for
      obstacle independence.
    
    	\startsubsection
        [reference=sec:defining_obstacles,
         title={Defining probabilistic obstacles}]
      
        Consider the
        goal \goal{Achieve [Make Up Pump Motor On When Water Requested]} requiring the pump motor to be
        turned on when requested by the operator. It is formalized
        by
        
        \startformula
          WaterPumpRequested \Rightarrow \ltlF_{\leq5m} WaterPumpMotor = \quote{\it On}
        \stopformula

        There is a domain property stating a necessary condition for the motor
        to be turned on, namely, the electrical relay is not be broken.
        
        \startformula
           WaterPumpMotor = \quote{\it On} \Rightarrow \neg PumpRelayBroken
        \stopformula
        
        By regression of the goal negation through this domain property,
        we obtain the obstacle \obstacle{Pump Electrical Failure}:
        
        \startformula
          \ltlF(WaterPumpRequested \wedge \ltlG_{\geq5m} PumpRelayBroken)
        \stopformula

        This condition captures the situation of the water pump not turned on
        due to a faulty relay. Such conditions should hopefully not be
        satisfied too often.

        \startdefinition{Obstacle satisfaction rate}

          The satisfaction rate of an obstacle of form $\ltlF (C \wedge \Theta
          OC)$ is the highest state probability of the assertion $C \wedge
          \Theta OC$ in any possible state $s$.

        \stopdefinition
        
        The satisfaction rate of an obstacle $O$ is denoted by $P(O)$. Dually
        to goals, we take a conservative approach requiring an upper bound as
        we need to pessimistically consider the highest chance of goal
        violation; thus, for an obstacle $\ltlF (C \wedge \Theta OC)$:
        
        \startformula
          P(O) = \max_{s\in S} P^s(C \wedge \Theta OC)
        \stopformula
        
        For example, consider a system with three states and the obstacle
        \obstacle{Pump Electrical Failure} specified above. Assume that
        
        \startformula
          WaterPumpRequested \wedge \ltlG_{\geq5m} PumpRelayBroken
        \stopformula
        
        has a state probability $.9$ in $s_1$; $.8$ in $s_2$; and $.7$ in
        $s_3$. The satisfaction rate for this obstacle is the largest state
        probability, that is, $.9$. The system satisfies

        \startformula
          \ltlG~\mathbb{P}_{\leq .9} (WaterPumpRequested \wedge \ltlG_{\geq5m} PumpRelayBroken)
        \stopformula
        
        Similarily to goals, the probability of $O$ over all behaviors
        satisfying some property $H$ is denoted by $P (O\mid H)$. 
        
        \startdefinition{Conditional obstacle satisfaction rate}
        
          The {\it conditional satisfaction rate} for an obstacle $O$ and a
          property $H$, denoted $P(O\mid{}H)$, is the satisfaction rate of $O$
          over the behaviors satisfying the property $H$. For an obstacle $O$
          of form $\ltlF(C \wedge \Theta OC)$, that is,
    
    		  \startformula
    			  P(O\mid{}H) = \max_{s \in S}P^s(\{\pi \in \,\graymath{\{\pi' \in Behaviors(s)\mid \pi' \vDash  \}}\,\mid \pi \vDash C \wedge \Theta OC\})
    		  \stopformula
        
        \stopdefinition
        
        In our probabilistic framework, obstacles are annotated with an
        estimated satisfaction rate.
        
        \startdefinition{Estimated obstacle satisfaction rate}

          The {\it estimated satisfaction rate} (ESR) of an obstacle is the
          satisfaction rate obtained from fine-grained estimates provided by
          domain experts.

        \stopdefinition
        
        \noindent The ESR of leaf obstacles in obstacle refinement trees is
        provided by domain experts based on their experience or available data;
        it is computed for non-leaf obstacles. \in{Chapter}[chap:assessing]
        will show how their computation proceeds by up-propagation through the
        refinement trees.
        
        Leaf obstacles are precise and ideally capture one single exceptionnal
        situation that is easier for the domain experts to estimate. The domain
        experts opinions and beliefs can be challenged with the precise
        characterization in terms of behaviors and states. It helps to reduce
        the subjective estimates provided by the domain experts.
        
        Obstacles are related to goals through the {\it obstruction} relation.
        An obstacle has to obstruct some goal, i.e., prevent the full
        satisfaction of the goal; and has to be consistent with the domain,
        i.e., the obstacle can happen. The obstruction and domain-consistency
        conditions for the non-probabilistic framework in
        \in{Section}[sec:background_goal] are generalized as accordingly:

        \startitemize

          \item The {\it obstruction} condition now states that the obstacle
          prevents the satisfaction of the obstructed goal.
        
  			  \startdefinition{Strong goal obstruction}
			
            A goal $G$ is {\it strongly obstructed} by an obstacle $O$ iff        
    			
            \startformula
              P (\neg G \mid O, Dom) = 1 
            \stopformula
        
          \stopdefinition

          \item The {\it domain-consistency} condition states that there is a
          chance for the obstacle to occur.
        
  			  \startdefinition{Domain consistency}		
        
            An obstacle $O$ is consistent with the domain iff
          
            \startformula
              P (O \mid Dom) > 0
            \stopformula
        
            The condition $O \wedge Dom$ has to be realizable by the environment
            monitoring the variables constrainted by the obstructed goal and
            controlling the others.
        
          \stopdefinition
        
        \stopitemize

        There again, the obstruction condition can be relaxed to account for
        partial obstruction. The relaxed condition states that there is a
        chance for the obstacle to violate the goal:
        
			  \startdefinition[def:partial-obstruction]{Weak goal obstruction}		
          
          A goal $G$ is {\it weakly obstructed} by an obstacle $O$ iff
    			
          \startformula
            P (\neg G \mid O, Dom) > 0
          \stopformula
        
        \stopdefinition
        
        Unless explicit, the thesis consider strong goal obstructions.
              
		  \stopsubsection
    
    	\startsubsection[reference=sec:modeling_probabilistic_obstacles,
        title={Probabilistic obstacles models}]
		  
        For an obstacle AND-refinement, the completeness, consistency and minimality
        conditions are similar to those introduced in
        \in{Section}[sec:modeling_probabilistic_goals] for probabilistic goals.
        
        \startitemize
        
        \item An AND-refinement of a probabilistic obstacle is complete if the
        satisfaction of the subobstacles is sufficient for the satisfaction of
        the parent obstacle.
        
        \startdefinition{Complete AND-refinement}
			
          A refinement of an obstacle $O$ into subobstacles $SO_1, ..., SO_n$
          is {\it complete} iff
  			
          \startformula
					  P (O\mid SO_1, ..., SO_n, Dom) = 1
    			\stopformula

        \stopdefinition
		
			  \item An AND-refinement of a probabilistic obstacle is consistent if at
			  least one behavior satisfies all subobstacles and domain properties.
        
        \startdefinition{Consistent AND-refinement}
			
          A refinement of an obstacle $O$ into subobstacles $SO_1, ..., SO_n$
          is {\it consistent} iff
  			
          \startformula
					  P (SO_1, ..., SO_n, Dom) > 0
    			\stopformula

        \stopdefinition
		
			  \item An AND-refinement of a probabilistic obstacle is minimal if
			  removing a subobstacle hinders the completeness of the refinement.
        
        \startdefinition{Minimal AND-refinement}
			
          A refinement of an obstacle $O$ into subobstacles $SO_1, ..., SO_n$
          is {\it minimal} iff
  			
          \startformula
					  P (O\ \mid \bigwedge_{j\neq i} SO_j, Dom) < 1\hskip1cm \text{for all $i$ s.t. $1 \leq i \leq n$}
    			\stopformula

        \stopdefinition
        
        \stopitemize

        \noindent For an OR-refinement, the subobstacles must entail their parent:
		
			  \startdefinition{Strong entailment}
        
          As strong OR-Refinement of an obstacle $O$ into subobstacles $SO_1,
          ..., SO_n$ must satisfy
        
          \startformula
            P (O \mid SO_i) = 1\hskip1cm \text{for all $i$ s.t. $1 \leq i \leq n$}
          \stopformula
          
        \stopdefinition
        
        \noindent This condition can be relaxed to support partial entailment.
		
			  \startdefinition[def:partial-obstacle-entailment]{Weak entailment}
        
          A weak OR-Refinement of an obstacle $O$ into subobstacles $SO_1, ..., SO_n$
          must satisfy
  			
          \startformula
            P (O \mid SO_i) > 0\hskip1cm \text{for all $i$ s.t. $1 \leq i \leq n$}
          \stopformula
          
        \stopdefinition

        Ideally, an obstacle refinement shall be domain-complete; all obstacles
        should have been identified within the domain. For an OR-Refinement,
        the condition states that the parent obstacle may not be satisfied
        through other obstacles.
		
			  \startdefinition{Domain completeness}
        
          An OR-Refinement of an obstacle $O$ into subobstacles $SO_1, ..., SO_n$
          is {\it domain complete} iff
        
          \startformula
            P (O \mid \neg SO_1, ..., \neg SO_n, Dom) = 0
          \stopformula
          
        \stopdefinition

      \stopsubsection
        
      \startsubsection
        [reference=ref:independence-obstacles,
         title={Independence among probabilistic obstacles}]
        
        In our example, the probability for the relay of the water pump to fail
        does not depend on, e.g., the probability of a leak in the spent fuel
        pool. Note such assumption must be carefully checked by domain experts.
        On the contrary, the satisfaction of a parent obstacle depends on the
        satisfaction of its children.
        
        \startdefinition[dfn:obstacleindependence]{Obstacle weak independence}
        
          Two obstacles are {\it weakly dependent} if the set of behaviors that
          satisfies one of them satisfies or denies the other. In terms of
          probabilities, $O_1$ depends on $O_2$ iff
        
          \startformula
            P (O_1\mid O_2) = 0\hskip1cm\text{ or }\hskip1cm P (O_1\mid O_2) = 1
          \stopformula
        
          Two obstacles are {\it weakly independent} if they are not weakly dependent.
        
        \stopdefinition
        
        The disjointness condition on subobstacles, recalled in
        \in{Section}[sec:background_obstacle], is generalized into a {\it
        strong independence} condition.
        
        \startdefinition[dfn:obstacleindependence]{Obstacle strong independence}
      
        Two obstacles are {\it strongly dependent} if the set of behaviors that
        satisfies one of them impacts the satisfaction or falsification of the
        other. In terms of probabilities, $O_1$ and $O_2$ are strongly
        dependent iff

        \startformula \startalign [n=3,align={right,left,left}]
          \NC P (O_1\mid O_2) \NC \neq P (O_1\mid \neg O_2) \NC \neq P (O_1), \NR
          \NC P (O_2\mid O_1) \NC \neq P (O_2\mid \neg O_1) \NC \neq P (O_2). \NR
        \stopalign \stopformula
      
        Two obstacles are {\it strongly independent} if they are not strongly
        dependent.
        
        \stopdefinition

        Ideally, leaf subobstacles in an OR-Refinement should be disjoint; the
        satisfaction of one leaf subobstacle should therefore not depends on
        the satisfaction of others. However, two dependent obstacle conditions
        $CO_1$ and $CO_2$ can be captured through three independent obstacles:
        $\neg CO_1 \wedge CO_2$, $CO_1 \wedge \neg CO_2$, and $CO_1 \wedge
        CO_2$. Each of these can then have a different probability. How to
        efficiently handle dependent obstacle still remains an open challenge.

        \startproposition
		  
          In an obstacle graph whose AND-refinements are complete, two
          obstacles are weakly dependent if they are connected through a
          refinement.
    
        \stopproposition
            
        \startproposition
	      
          In a minimal, complete and consistent obstacle refinement, the
          subobstacles are weakly independent.
        
        \stopproposition
        
        \noindent The proofs are similar to the ones provided for goal
        refinements.

      \stopsubsection
      
    \stopsection
  
    \startsection
		  [reference=sec:formal-spec-probabilistic,
		   title={Formal Specification of Probabilistic Goals and Obstacles}]
    
      To enable formal verification techniques, probabilistic goals with a
      required satisfaction rate may be formalized using the PCTL/PCTL* formalism
      recalled in \in{Section}[sec:pctl]. This section introduces specification
      patterns for probabilistic goals similar to the specification patterns
      available for non-probabilistic goals.
    
      A probabilistic goal of form $C\rightarrow\Theta T$, where $\Theta$
      denote a temporal operator such as $\ltlF$ or $\ltlG$, with a required
      satisfaction rate $rsr$ may be formalized by the following PCTL* assertion
        
      \startformula
        
        \ltlG \mathbb{P}_{\geq rsr}(C\rightarrow\Theta T)
        
      \stopformula
        
      where the assertion $\ltlG {\blackboard{}P}_{\geq rsr}(\phi)$ is
      satisfied by a behavior $\pi$ if all states $s$ along this behavior
      satisfy $\mathbb{P}^s_{\geq rsr}(\phi)$. To ease the specification of
      such probabilistic goals, we introduce the following shorthand notation
      similar to the operator \quote{leads to} introduced in \cite[Han94]
    
      \startformula
        C \Rightarrow_{\geq p} \Theta T \hskip.5cm \equiv\hskip.5cm  \mathbb{P}_1 [ \ltlG \mathbb{P}_{\geq p} [ C \rightarrow \Theta T ] ]
      \stopformula
      
      where $\mathbb{P}_1$ requires the probability of the enclosed assertion
      to equal $1$. This operator can also be formalized in PCTL as
        
      \startformula
      	\mathbb{P}_1 [ \ltlG (C \rightarrow \mathbb{P}_{\geq p} [ \Theta T ]) ]
      \stopformula
        
   %  \startproposition
   %    
   %    The PCTL* formula $\mathbb{P}_1 [ \ltlG \mathbb{P}_{\geq p} [ C
   %    \rightarrow \Theta T ] ]$ and the PCTL formula $\mathbb{P}_1 [ \ltlG (C
   %    \rightarrow \mathbb{P}_{\geq p} [ \Theta T ]) ]$ are equivalent.
   %  
   %  \stopproposition
   %    
   %  \startproof Let decompose the proof in two parts: {\it (a)} In a state
   %  where $C$ is true, the PCTL sub-formula $C \rightarrow \mathbb{P}_{\geq
   %  p} [ \Theta T ]$ is reduced to $\mathbb{P}_{\geq p} [ \Theta T ]$, and
   %  the PCTL* sub-formula $\mathbb{P}_{\geq p} [ C \rightarrow \Theta T ]$ is
   %  reduced to $\mathbb{P}_{\geq p} [ \Theta T ]$; both are trivially
   %  equivalent. {\it (b)} In a state $s$ where $C$ is false, the PCTL
   %  sub-formula $C \rightarrow \mathbb{P}_{\geq p} [\Theta T ]$ is reduced to
   %  $True$, and the PCTL* sub-formula $\mathbb{P}_{\geq p} [ C \rightarrow
   %  \Theta T ]$ is reduced to $\mathbb{P}_{\geq p} [ True ]$. The latter is
   %  trivially equivalent to $True$. \stopproof
      
      Formalizing probabilistic requirements is a tedious and error-prone task,
      even though it is required for formal and automated reasoning.
      Specifications patterns encode common formalizations to ease the
      specification of probabilistic goals. Here we provide some probabilistic
      specification patterns generalizing common specification patterns
      presented in \cite[Dar95].
      
      \noindent\bold{Probabilistic {\bi Achieve} and {\bi Cease}}. An
      \italic{Achieve} goal (respectively \italic{Cease} goal) requires a
      target condition to be true (respectively false) at some point in the
      future when a current condition is satisfied. The time elapsed between
      the states satisfying the current and target conditions must be bounded
      for finite violability. In LTL, this is formalized as:
      
      \startformula
        C \Rightarrow \ltlF_{\bowtie t} T \hskip.5cm\text{\it(Achieve)}
        \text{\hskip1cm or \hskip1cm} 
        C \Rightarrow \ltlF_{\bowtie t} \neg T \hskip.5cm\text{\it(Cease)}
      \stopformula
      
      where $\bowtie$ is a comparison operator such as $>, <, \leq, \geq$, or $=$.
      
      This probabilistic version for an {\it Achieve} goal (respectively {\it
      Cease} goal), states that a target condition is achieved (respectively
      not achieved) from a current condition with some probability above a
      specified threshold $p$. Such specification patterns are also sometimes
      referred as Probabilistic Response \cite[Gru08]. In PCTL*, this may be
      formalized as:
      
      \startformula
        C \Rightarrow_{\geq p} \ltlF_{\bowtie t} T \hskip.5cm\text{\it(Achieve)}
        \text{\hskip1cm or \hskip1cm} 
        C \Rightarrow_{\geq p} \ltlF_{\bowtie t} \neg T \hskip.5cm\text{\it(Cease)}
      \stopformula
      
      For example, the goal \goal{Achieve [Alarm Raised When Low Water]} with a
      required satisfaction rate of $.95$ corresponds to the probabilistic {\it
      Achieve} specification pattern:
 
      \startformula
        WaterLevel \leq LOW \Rightarrow_{\geq.95} \ltlF_{< 5 \text{min}} AlarmRaised
      \stopformula
      
      \noindent\bold{Probabilistic {\bi Maintain} and {\bi Avoid}.} A
      \italic{Maintain} goal, (respectively an \italic{Avoid} goal) states that
      a target condition always remains true (respectively false) given some
      condition on the current state. The time for which the target condition
      is true may be bounded or not. In LTL, this is formalized as:
      
      \startformula
        C \Rightarrow \ltlG_{\bowtie t} T \hskip.5cm\text{\it(Maintain)}
        \text{\hskip1cm or \hskip1cm} 
        C \Rightarrow \ltlG_{\bowtie t} \neg T \hskip.5cm\text{\it(Avoid)}
      \stopformula
      
      The probabilistic counterpart to a {\it Maintain} states that the target
      condition must hold with at least some given probability. For a
      probabilistic {\it Avoid} goal, the target condition may not hold. This
      can be formalized as
      
      \startformula
        C \Rightarrow_{\geq p} \ltlG_{\bowtie t} T \hskip.5cm\text{\it(Maintain)}
        \text{\hskip1cm or \hskip1cm} 
        C \Rightarrow_{\geq p} \ltlG_{\bowtie t} \neg T \hskip.5cm\text{\it(Avoid)}
      \stopformula
      
      For example, the goal \goal{Maintain [Water Temperature Below 54]} with a
      required degree of satisfaction of $.95$ corresponds to the probabilistic
      {\it Maintain} specification pattern:
      
      \startformula
        True \Rightarrow_{\geq .99}(\ltlG_{\geq 30\,min}(WaterTemperature < 54)
      \stopformula
      
  \stopsection
  
  \startsection[title={Summary}]
  
    This chapter introduced probabilistic goals and probabilistic obstacles
    together with a precise definition in terms of state and behaviors. This
    characterization helps reducing subjective estimates provided by domain
    experts. Correctness conditions on the goal/obstacle model structure were
    generalized to support both probabilistic goals and obstacles. The
    satisfaction arguments there were formulated in terms of contraints on
    probabilities. The independence of probabilistic goals and obstacles is
    important for accurate estimates. The chapter provided precise
    characterization of the independence for probabilistic goals and obstacles.
    It showed how such characterization might be enforced by leveraging the
    refinement structure. The chapter also showed how the specification of
    probabilistic goals may be facilitated by use of specification patterns to
    enable formal analysis.
    
    This chapter provides the basis for the assessment and control techniques
    of probabilistic obstacles as elaborated in the next two chapters. In
    addition, the proposed characterization in terms of states and behaviors
    enables the monitoring, at system runtime, the probabilistic obstacles for
    dynamic model adaptation, as \in{Chapter}[runtime] will show.
  
  \stopsection
  
\stopchapter

\stopcomponent
