% !TEX root = thesis.tex

\startcomponent chap-4
\environment common
\product thesis

\chapter
	[reference=chap:assessing,
   list={Assessing the Likelihood and Criticality of Obstacles},
   bookmark={Assessing Likelihood and Criticality of Obstacles},
   marking={Assessing Likelihood and Criticality of Obstacles},
	 title={\framed[align=normal,frame=off]{Assessing Likelihood \\ and Criticality of Obstacles}}]


  In standard risk analysis, the identified risks are assessed in terms of
  their likelihood and the likelihood of their consequences. Determining these
  likely and critical  risks is an important prerequisite for determining
  appropriate countermeasures. Risk prioritization is commonly performed by
  comparing risk likelihoods, the likelihood of risk consequences and the
  severity of those consequences.
  
  In goal-oriented RE, risks are captured by obstacles and consequences are
  expressed as loss in satisfaction of the obstructed goals. This chapter
  explains how likely and critical obstacles are identified. It shows how the
  satisfaction rate of finer-grained probabilistic obstacles are estimated, how
  the satisfaction rate of higher-level probabilistic obstacles and higher-level
  probabilistic goals are computed from the estimated satisfaction rate of
  those finer-grained probabilistic obstacles, that is, leaves in obstacle
  refinement trees.

  The satisfaction rate of a leaf obstacle is estimated by domain experts as a
  single-value probability that can be combined with other single-value
  probabilities for more accurate estimates. The satisfaction rate of a
  higher-level obstacle is obtained by up-propagation from the leaf obstacles. The
  satisfaction rate of these probabilistic obstacles determines likely
  obstacles.
  
  The critical obstacles are those causing a major drop in satisfaction rate of
  high-level goals. The criticality of an obstacle is obtained by computing the
  satisfaction rate of the obstructed goals. The satisfaction rate of these is
  computed by up-propagation from the root obstacles to the leaf goals; and
  from the leaf goals to the high-level goals.
  
  Two up-propagation techniques are proposed: a BDD-based propagation that
  provides fast satisfaction rate computation at increased pre-computation
  cost; and a pattern-based propagation that provides finer-grained estimates
  at increased specification cost.
  
  Determining the likely and critical obstacles amounts to finding those likely
  obstacle combinations maximizing the drop in high-level goal satisfaction
  rates. As a result, the next {\it control} step might then focus on likely and
  critical obstacles to increase the completeness, accuracy and adequacy of the
  requirements.

  The chapter is organized as follows. \in{Section}[sec:estimating_satrate]
  details how leaf obstacles are estimated. \in{Section}[sec:computing_satrate]
  details how the satisfaction rate of high-level goals is computed from the
  estimated leaf obstacles.
  \in{Section}[sec:indentifying_most_critical_obstacles] details how comparing
  the satisfaction rate with the high-level goals to their respective required
  satisfaction rate allow likely and critical obstacles to be determined.
    
  \startsection
    [title={Estimating the satisfaction rate of leaf obstacles},
     reference=sec:estimating_satrate]

    The first phase is to collect the estimates for the satisfaction rate of
    leaf obstacles. Theses will be up-propagated next to compute the
    satisfaction rate of higher-level obstacles and then of obstructed goals in
    the goal model.
    
    The satisfaction rate of the leaf obstacles might be available from
    historical data, measurements, specification sheets provided by
    contractors, etc. However, such data migth not be available for cost
    reasons, technical difficulties, system uniqueness or some practical
    limitation. The estimation of satisfaction rates therefore often relies on
    expert judgement.
    
    To obtain more accurate estimates from domain experts, we proceed in two
    steps: single, fine-grained estimates are obtained from a diversity of
    domain experts (\in{Section}[sec:asfge]) and those estimates are combined
    (\in{Section}[sec:combining_sat_rate]).

    \startsubsection [reference=sec:asfge,title={Acquiring single fine-grained estimates}]

      We propose the following approach, inspired from risk analysis as seen in
      \cite[OHa06a, Otw92], for getting estimates for the satisfaction rate of
      leaf obstacles.
    
      \startitemize[n]

        \item Select the leaf obstacles to be estimated by domain experts.
        These are the ones for which no data are available.

        \item Identify, select, and train the domain experts. The selected
        experts should provide a diversity of judgements, be independent in
        their knowledge sources, and trained to make sure they understand the
        models and the techniques. How to select experts is discussed in
        \cite[Vos08,OHa06a,Otw92]. A a detailed discussion on the elicitation
        techniques, biais identification, and de-biasing techniques is
        available in \cite[Coo91,Vos08].

        \item Elicit the satisfaction rate of the selected leaf obstacles from
        the selected experts. Techniques and pitfalls for such elicitation
        sessions are described in \cite[OHa06a,Vos08]. Note that the structure
        of the goal and obstacle models might be modified by the experts during
        this assessement step.

        \item Aggregate and analyze the results. The next section overviews
        techniques for combining multiple expert assessments.

        \item Document all elements from this process, in particular, what
        obstacles were estimated, how experts were selected and trained, and
        what raw estimates are provided by the experts. This enables future
        evaluation by independent experts.

      \stopitemize
    
    \stopsubsection
    
    \startsubsection
      [title={Combining estimated satisfaction rates},
       reference=sec:combining_sat_rate]
      
      The use of multiple sources or multiple experts is generally recognized
      to increase the accuracy of estimates \cite[Coo91]. The problem is then
      to combine the satisfaction rates provided by multiple experts into a
      single satisfaction rate. The latter will be up-propagated next through
      obstacle and goal trees. Informal techniques are often used in practice
      to reach a consensus on a single value agreed by all experts
      \cite[OHa06a, Vos08]. More mathematical approaches are however recognized
      to produce more accurate results than informal ones \cite[Bed01].
      
      Among the mathematical approaches, we mainly distinguish two combination
      schemas: bayesian combinations and non-bayesian combinations.
      
      Bayesian combination techniques rely on Bayes' theorem for combining
      probabilities. However, theses techniques require and produce a
      probability distribution. This discussion is therefore deferred to
      \in{Section}[sec:eliciting_more_accurate_estimates] where uncertainties
      in the estimates are introduced through distribution functions.
      
      Non-Bayesian combination techniques do not require probability
      distributions. These include standard combinations such as taking the
      smallest or the largest satisfaction rate or averaging the satisfaction
      rates. These combination may be generalised by a {\it r-norm}
      \cite[Bed01,Coo91]. There we discuss $r$-norm-based combinations
      specialized to probabilistic obstacles, as inspired by \cite[Bed01].
      
      The {\it r-norm satisfaction rate} combines the satisfaction rate of
      multiple domain experts by weighting domain experts with their relative
      importance and smoothing out variations.
      
      \startdefinition{$r$-norm satisfaction rate}
      
        The {\it $r$-norm satisfaction rate}, denoted $P_r(A)$, for an assertion $A$
        is given by
      
        \startformula
          P_r(A) = \left(\sum_{e \in Experts} w_e \left[P_e(A)\right]^r\right)^{1/r}
        \stopformula
      
        where $w_e$ is the weight assigned to the expert $e$ and $P_e(A)$ is
        the probability estimated by the expert $e$ for the assertion $A$.
        Weights should sum to $1$.
      
      \stopdefinition
      
      Picking the right weight for the experts is an important step; how to
      assign weights to experts is discussed in \cite[OHa06a, Bed01, Coo91]. In
      the example below, we use equal weight for all experts.
      \in{Section}[sec:eliciting_more_accurate_estimates] shows how weights can
      be systematically determined when estimates are uncertain.
      
      Depending on the value given to the parameter $r$, the norm corresponds
      to different combinations \cite[Bed01,Coo91]. For example, consider the
      obstacle \obstacle{Power Cabling Failure} in
      \in{Figure}[fig:or_and_obstacle_refinement], estimated by two different
      experts $e, e'$ as follows:

      \startformula 
        P_{e}(\text{\obstacle{Power Cabling Failure}}) = .3\hskip.5cm\text{ and }\hskip.5cmP_{e'}(\text{\obstacle{Power Cabling Failure}}) = .1
      \stopformula

      \placefigure[top]
      	[fig:or_and_obstacle_refinement]
      	{An obstacle refinement tree.}
        {\externalfigure[../images/chap4/or_and_obstacle_refinement.pdf]}

      \startitemize[packed,nowhite]
        
        \item The $\infty\text{-norm}$ amounts to taking the largest
        satisfaction rate. The $r$-norm satisfaction rate is:
        
          \startformula P_\infty(\text{\obstacle{Power Cabling Failure}}) = .3 \stopformula
        
        \item The $-\infty\text{-norm}$ amounts to taking the
        smallest satisfaction rate. The $r$-norm satisfaction rate is:
        
          \startformula P_{-\infty}(\text{\obstacle{Power Cabling Failure}}) = .1 \stopformula
          
        \item The $0\text{-norm}$ corresponds to a geometric mean.
        The $r$-norm satisfaction rate is:
              
          \startformula 
            P_0(\text{\obstacle{Power Cabling Failure}}) = \sqrt{.3\times.1} = 
              \ctxlua{tex.print(string.format("\letterpercent.2f", math.sqrt(.3*.1)))}
          \stopformula

        \item The $1\text{-norm}$ corresponds to an arithmetic mean.
        The $r$-norm satisfaction rate is:

          \startformula 
            P_1(\text{\obstacle{Power Cabling Failure}}) = \frac{.3 + .1}{2} =
              \ctxlua{tex.print(string.format("\letterpercent.2f", (.3+.1)/2))}
          \stopformula

      \stopitemize
      
      As shown in the example above, the $r$-norm satisfaction rate depends on
      parameter $r$. Which {\it $r$-norm satisfaction rate} to chose depends on
      which properties for the combined estimate are desirable among the
      following ones.
      
      \startitemize

        \item {\bf Zero Preservation}. If all expert estimates that the
        satisfaction rate of an obstacle is zero, the $r$-norm satisfaction
        rate should be zero. This property is satisfied for all {\it r-norms}.

        \item {\bf Marginalization}. The $r$-norm satisfaction rate should not
        depend on how the obstacle is OR-Refined. In other words, given an
        obstacle $O$ OR-refined in two disjoint subobstacles $SO_1$, $SO_2$,
        the $r$-norm satisfaction rate should satisfy
        
        \startformula 
          P_r(O) =  P_r(SO_1) + P_r(SO_2).
        \stopformula
        
        \indentation For example, consider two experts estimating the
        subobstacles of the OR-Refinement in
        \in{Figure}[fig:or_and_obstacle_refinement]. The first expert estimates
        $.1$ for \obstacle{Power Cabling Failure} and $.2$ for \obstacle{UPS
        Battery Failure}. The second expert estimates $.2$ for \obstacle{Power
        Cabling Failure} and $.1$ for \obstacle{UPS Battery Failure}. (For
        simplicity, we ignore the subobstacle \obstacle{Power Supply Failure}.)
        As we will show in \in{Section}[sec:computing_satrate], both experts
        estimate that the satisfaction rate of the parent obstacle \obstacle{No
        Power Available} is $.1 + .2 = .3$.
        
        \noindent Using a {\it $0$-norm} for combining the satisfaction rate of the
        subobstacles yields $\sqrt{.2 \times .1} = .14$ for both subobstacles.
        With these combined estimates, the satisfaction rate of the parent
        obstacle is $.14 + .14 = .28$.
        
        \noindent With the {\it $1$-norm}, however, the $r$-norm satisfaction rate of
        both subobstacle is $.5\times(.2 + .1) = .15$. In that case, the
        satisfaction rate of the parent obstacle is $.3$, as the experts have
        independently estimated those quantities.
        
        The {\it $1$-norm} is known to be the only {\it $r$-norm} to exhibit
        the marginalization property \cite[Bed01].

        \item {\bf Independence Preservation}. The $r$-norm satisfaction rate
        should not depend on how the obstacle is AND-Refined. In other words,
        given an obstacle $O$ AND-refined in two independent subobstacles
        $SO_1$, $SO_2$, the $r$-norm satisfaction rate should satisfy:
        
        \startformula 
          P_r(O) =  P_r(SO_1) \times P_r(SO_2).
        \stopformula
        
        \indentation For example, consider the AND-refinement depicted in
        \in{Figure}[fig:or_and_obstacle_refinement]. The first expert estimates
        $.1$ for the obstacle \obstacle{Diesel Generator Failure} and $.2$ for
        \obstacle{Primary Power Supply Down}. The second expert estimate $.2$
        for \obstacle{Diesel Generator Failure} and $.1$ for \obstacle{Primary
        Power Supply Down}. Considering experts independently, they both
        estimate the satisfaction rate of the parent obstacle \obstacle{Power
        Supply Failure} to be $.1 \times .2 = .02$.
        
        \noindentation Using {\it $1$-norm} to combine their estimates, we
        obtain $.15$ for both subobstacles. The satisfaction rate of the
        parent obstacle is therefore $.15 \times .15 = .0225$, which differs
        from the estimate they provided independently.
        
        \noindentation Using {\it $0$-norm}, the $r$-norm satisfaction rate of
        the subobstacle is $\sqrt{.2\times .1}$. The satisfaction rate of the
        parent obstacle $O$ is $(\sqrt{.2\times .1})^2 = .02$.
        
        The {\it $0$-norm} has the independence preservation property unlike
        the {\it $1$-norm} \cite[Bed01].
        
      \stopitemize
    
    \stopsubsection
  
  \stopsection
    
	\section
    [title={Computing satisfaction rates of higher-level obstacles and goals},
     reference=sec:computing_satrate]

    The previous section showed how the satisfaction rate of leaf obstacles can
    be estimated from multiple domain experts. The second phase consists of determining
    the satisfaction rates of higher-level obstacles and then of
    high-level goals in the goal model from these estimated satisfaction rates.
    For obstacle assessment, the former satisfaction rate provides obstacle
    likelihoods whereas the latter satisfaction rate provide obstacle
    severities. This section shows two propagation techniques for computing the
    satisfaction rate of higher-level obstacles and goals.
    
    \startsubsection
      [reference=sec:computing_bdd,title={BDD-based computation of satisfaction rates}]

      A first procedure for computing the satisfaction rate of obstacles and 
      goals in a goal model can be outlined as follows. 
      
      \startitemize
      
        \item To compute the satisfaction rate of an obstacle, the set of
        AND-combinations of leaf obstacles entailing a given obstacle in the
        obstacle model is computed; this set is called the {\it entailment
        superset}.

        \item To compute the satisfaction rate of a goal, the set of
        AND-combination of leaf obstacles obstructing a given goal in the goal
        model is then computed; this set is called the {\it obstruction superset}.
      
      \stopitemize
      
      Those sets are encoded as a binary decision diagram (BDD) \cite[Bry92]
      (\in{Section}[sec:computing_obstruction_set]). Based on the estimated
      satisfaction rate of the leaf obstacles, the probability for the
      obstruction or entailment superset is computed
      (\in{Section}[sec:computing_sat_rate].)
            
  		\startsubsubsection
        [title={Computing entailement and obstruction sets},
         reference=sec:computing_obstruction_set]

        For a given obstacle $O$ in the obstacle model, we need to compute all
        AND-combinations of leaf obstacles and domain properties/hypotheses
        that may entail $O$. 
                
        \startdefinition{Obstacle entailment set}
          
          An {\it entailment set} for an obstacle $O$ is a set of obstacles $O_i$
          and domain properties/hypotheses $DH_j$ such that this set
          entails the obstacle and is {\it consistent}, that is,

          \startformula
            \startalign[n=1]
              \NC \{O_1, O_2, ..., DH_1, DH_2, ...\} \vDash O \NR[+]
              \NC \{O_1, O_2, ..., DH_1, DH_2, ... \} \nvDash false \NR[+]
            \stopalign
          \stopformula
        
        \stopdefinition

        For a given goal $G$ in the goal model, we need to compute all
        AND-combinations of leaf obstacles and domain properties/hypotheses
        that may obstruct $G$. 
        
        \startdefinition{Goal obstruction set}
          
          An {\it obstruction set} for a goal $G$ is a set of obstacles $O_i$
          and domain properties/hypotheses $DH_j$ such that this set
          obstructs the goal and is {\it consistent}, that is,

          \startformula
            \startalign[n=1]
              \NC \{O_1, O_2, ..., DH_1, DH_2, ...\} \vDash \neg G \NR[+]
              \NC \{O_1, O_2, ..., DH_1, DH_2, ... \} \nvDash false \NR[+]
            \stopalign
          \stopformula
        
        \stopdefinition

        An entailment set $OS$ for an obstacle $O$ should be
        {\it minimal}, that is, all its elements are required for falsifying
        the goal:
      
        \startformula
          \startalign
            \NC \text{for all } O_i \text{ in } OS: \NC OS \setminus O_i \nvDash O	\NR
            \NC \text{for all } DH_j  \text{ in }  OS: \NC OS \setminus DH_j \nvDash O	\NR
          \stopalign
        \stopformula 
        
        Similarily, an obstruction set $OS$ for a goal $G$ should be {\it minimal},
      
        \startformula
          \startalign
            \NC \text{for all } O_i \text{ in } OS: \NC OS \setminus O_i \nvDash \neg G	\NR[eq:minimal_o_os]
            \NC \text{for all } DH_j  \text{ in }  OS: \NC OS \setminus DH_j \nvDash \neg G \NR[eq:minimal_d_os]
          \stopalign
        \stopformula 
        
        For example, the goal \goal{Achieve [Make Up Pump Motor On When Water
        Requested]}, shown in \in{Figure}[fig:make_up_water_pump_on], can be
        obstructed by the following four obstruction sets:

        \startitemize[packed]
          \item \{\obstacle{Pump Mechanical Failure}\}, 
          \item \{\obstacle{Diesel Generator Failure}, \obstacle{Primary Power Supply Down}\}, 
          \item \{\obstacle{Power Cabling Failure}\}, 
          \item \{\obstacle{UPS Battery Failure}\}.
        \stopitemize
        
        \placefigure[bottom]
        	[fig:make_up_water_pump_on]
        	{Obstacles for \goal{Achieve [Make Up Pump Motor On When Water Requested]}.}
          {\externalfigure[../images/chap4/make_up_water_pump_on.pdf]}

        As the example shows, a goal might have multiple alternative
        obstruction sets. Similarily, an obstacle might have multiple alternative
        entailment sets.
        
        \startdefinition{Entailment superset}
        
          The OR-combination of all alternative entailment sets for an
          obstacle $O$ is called {\it entailment superset} for $O$. It is
          denoted by $ES (O)$.
        
        \stopdefinition
        
        \startdefinition{Obstruction superset}
        
          The OR-combination of all alternative obstruction sets for a
          goal $G$ is called {\it obstruction superset} for $G$. It is
          denoted by $OS (G)$.
        
        \stopdefinition
        
        In the example, the obstruction superset for \goal{Achieve [Pump A
        Activated Until Measured Water Level Appropriate]} is the set
        containing all obstruction sets above.
      
        The entailment sets, respectively the obstruction sets, in an
        entailement superset, respectively an obstruction superset, should
        ideally be independent:

        \startdefinition{Dependent entailment sets}
 
          Two entailment sets $ES, ES'$ are {\it dependent} if they share a
          common obstacle or domain property/hypothesis, that is,
        
          \startformula
            \text{for all } ES, ES’ \text{ in } ES(O):  ES \cap ES’ \neq \varnothing
          \stopformula
          
          Two entailment sets are {\it independent} if they are not dependent.
        
        \stopdefinition

        \startdefinition{Dependent obstruction sets}
 
          Two obstruction sets $OS, OS'$ are {\it dependent} if they share a
          common obstacle or domain property/hypothesis, that is,
        
          \startformula
            \text{for all } OS, OS’ \text{ in } OS(G):  OS \cap OS’ \neq \varnothing
          \stopformula
          
          Two obstruction sets are {\it independent} if they are not dependent.
        
        \stopdefinition
        
        Such dependences arise when obstruction sets share common obstacles or
        domain hypotheses.

        The entailement superset for an obstacle is computed by up-propagation
        through obstacle refinement tree from the leaf obstacles and domain
        properties/hypotheses in obstacle trees to their root obstacle. The
        obstruction superset for a goal is then computed by up-propagation from
        the root obstacle to the corresponding obstructed leaf goals and finally
        from the leaf goals in goal trees to the considered higher-level goal.

        \noindent {\bf Step 1: From leaf obstacles to root obstacles.} Consider
        the obstacle AND/OR refinement tree anchored on a leaf goal $LG$ in the
        goal model. To obtain the obstruction superset $OS (LG)$, we proceed by
        structural induction. 
      
        \startitemize
          \item For a leaf obstacle or a domain hypothesis LO:
            \startformula
              ES (LO) = \{LO\}
            \stopformula
          \item For an AND-refinement of $O$ in subobstacles $SO_1$ and $SO_2$: 
            \startformula
              ES(O) =  ES(SO_1) \times ES(SO_2),
          \stopformula
      
          where $\times$ denotes the cartesian product over sets.

          \item For an OR-refinement of $O$ in subobstacles $SO_1$ and $SO_2$:
            \startformula
              ES (O) = ES (SO_1) \cup ES (SO_2).
            \stopformula
            
            \noindent (The generalization to refinements involving more
            subobstacles is straightforward.)
          
        \stopitemize

        For example, the entailment superset for the obstacle \obstacle{Power
        Supply Failure} in \in{Figure}[fig:or_and_obstacle_refinement] is
        \{\{\obstacle{Diesel Generator Failure}, \obstacle{Primary Power Supply
        Down}\}\}; The entailment superset for the obstacle \obstacle{No Power
        Available} is \{\{\obstacle{Diesel Generator Failure},
        \obstacle{Primary Power Supply Down}\}, \{\obstacle{Power Cabling
        Failure}\},\{\obstacle{UPS Battery Failure}\}\}. The entailment
        superset for the root obstacle \obstacle{Pump Motor Not On And
        Requested} in \in{Figure}[fig:make_up_water_pump_on] contains the two
        extra entailment sets \{\obstacle{Pump Mechanical Failure}\} and
        \{\obstacle{Pump Electrical Failure}\}.

        \noindent {\bf Step 2: From root obstacles to leaf goals.} The
        obstruction superset for a leaf goal $LG$ obstructed by a root obstacle
        $RO$ is:

        \startformula
          OS (LG) = ES (RO)
        \stopformula
      
        In our example, the obstruction superset for the goal \goal{Achieve
        [Make Up Pump Motor On When Water Requested]} is the entailment
        superset for the corresponding root obstacle \obstacle{Pump Motor Not
        On And Requested}.

        \noindent {\bf Step 3: From leaf goals to top goals.} In the goal
        AND/OR refinement graph, the obstruction superset for a parent goal
        depends on the obstruction superset for its subgoals. For a parent goal
        $PG$ AND-refined into subgoals $SG_1$ and $SG_2$ we have:

        \startformula 
          OS (PG) = OS (SG_1) \cup OS (SG_2)
        \stopformula
        
        \noindent (The generalization to AND-refinements with more subgoals is
        straightforward.)

        We do not consider OR-refinement of goals here. OR-refinements of goals
        capture alternative systems; here we focus on a single system.

        The obstruction sets in the superset thereby obtained are not
        necessarily independent. This arises from obstacle refinement trees
        sharing common obstacles, resulting in non-empty intersections of
        obstruction sets. Such dependencies must be taken into account when
        computing the probability of satisfaction of obstruction sets. This can
        be achieved automatically, see \in{Section}[sec:computing_sat_rate].
        Obstruction sets are minimal if goal and obstacle refinements are
        minimal.

        Consider the goal refinement presented in
        \in{Figure}[fig:make_up_water_provided]. The obstruction superset for
        the goal \goal{Achieve [Make Up Water Provided When Loss Of Cooling]}
        may be computed from the obstruction supersets obtained for the
        subgoals \goal{Achieve [Make Up Water Requested When Loss Of Cooling]}
        and \goal{Achieve [Make Up Water Provided When Requested]}.
        Recursively, the obstruction superset for the goal \goal{Achieve [Make
        Up Water Requested When Loss Of Cooling]} may be computed from the
        obstruction superset for the goals \goal{Achieve [Alarm Raised When Low
        Water]} and \goal{Achieve [Make Up Water Requested When Alarm Raised]}.

        \placefigure[bottom]
        	[fig:make_up_water_provided]
        	{Refinement of \goal{Achieve [Make Up Water Provided When Loss Of Cooling]}.}
          {\externalfigure[../images/chap4/make_up_water_provided.pdf]}

        \indentation An entailment/obstruction superset somewhat corresponds to
        the {\it cut set} of a fault tree \cite[Bed01,Lam09]. However, a cut
        set yields all combinations of leaf events causing the root event to
        occur, like an entailment superset, whereas an obstruction superset
        yields all combinations of leaf obstacles causing the corresponding
        goal in the goal model to be obstructed. The propagation must therefore
        continue bottom-up through the goal model with specific propagation
        equations to assess the severity of obstruction consequences\emdash{}see
        Step 2 and Step 3, not found in Fault Tree Analysis. Another difference
        is that the tree nodes here are formalizable goal/obstacle
        specifications, linked by entailment relationships among levels, rather
        than event labels.
        
      \stopsubsubsection
      
  		\startsubsubsection
        [title={Computing satisfaction rates from obstruction sets},
         reference=sec:computing_sat_rate]
         
        The previous section showed how the entailment and obstruction superset
        can be obtained for a higher-level obstacle or goal. The satisfaction
        rate of a higher-level obstacle or goal is computed as follows: {\it
        (1)} A binary-decision diagram (BDD) is built; {\it (2)} Probability
        values are up-propagated through the BDD tree, from the leafs to the
        root node; {\it (3)} The satisfaction rate of the higher-level obstacle
        or goal is computed from the probability value of the root node.
        
        \noindent {\bf Step 1: Building the BDD.} To compute the probability of
        satisfaction of an entailement or obstruction superset next, a BDD is
        built that represents the corresponding Boolean formula where each leaf
        obstacle and domain hypothesis appears as a variable. This Boolean
        formula encodes the AND/OR-combination of leaf obstacles and domain
        hypotheses through the disjunction of the conjunction of elements in
        each obstruction set. As the ordered BDD is canonical, equivalent
        formulas result in the same BDD. This makes specific treatments of
        dependent entailment or obstruction sets unnecessary; a superset with
        dependent sets will result in the same BDD than an equivalent superset
        with independent sets.
        
        In our example, consider the goal \goal{Achieve [Make Up Pump Motor On
        When Water Requested]} (see \in{Figure}[fig:or_and_obstacle_refinement]
        and \in{Figure}[fig:make_up_water_pump_on]). Its obstruction sets given
        before, correspond to the following Boolean formula:
      
        \startformula\openup -5pt \startalign[n=1,align=left]
          \NC \text{\obstacle{Pump Mechanical Failure}} \NR
          \NC \vee (\text{\obstacle{Diesel Generator Failure}} \wedge \text{\obstacle{Primary Power Supply Down}})\NR
          \NC \vee \text{\obstacle{Power Cabling Failure}} \NR
          \NC \vee \text{\obstacle{UPS Battery Failure}} \NR
          \NC \vee \text{\obstacle{Pump Electrical Failure}}\NR
        \stopalign\stopformula

        Efficient algorithms are available for building compact BDDs
        \cite[Ebe05,Mei12]. Such BDDs enable fast computation of single-point
        probability values from single-point probability values for the
        variables \cite[Bed01]. \in{Figure}[fig:bdd] shows a BDD corresponding
        to the preceding formula. Each node represents a leaf obstacle. By
        following the solid edge if the corresponding leaf obstacle is
        satisfied or the dotted edge otherwise, we can determine whether the
        corresponding Boolean formula is {\it true} or {\it false}. The
        terminal nodes indicate whether the formula is satisfied (1) or not
        (0). For example, if \obstacle{Diesel Generator Failure} and
        \obstacle{Primary Power Supply Down} are both satisfied, the
        obstruction set is satisfied since the BDD path ends at node (1).
        
        \placefigure[bottom]
        	[fig:bdd]
        	{BDD for the obstruction set of \goal{Achieve [Make Up Pump Motor On When Water Requested]}.}
          {\externalfigure[../images/chap4/bdd.pdf]}
        
        \noindent {\bf Step 2: Propagating probability values.} Every edge in
        the BDD has a probability label. The probability label for a solid edge
        corresponds to the estimated satisfaction rate of the leaf obstacle at
        its source; for a dotted edge, the probability label corresponds to 1
        minus this probability.

        The probability of a non-terminal node captures the probability that
        the formula corresponding to the sub-tree is satisfied. It is given by
        the product of the probability on the edge and the probability of the
        target node. For a terminal node, the probability is given by its value
        ($0$ or $1$).

        \startluacode
          eps_o_diesel = 0.01
          eps_o_primary = 0.05
          eps_o_cabling = 0.02
          eps_o_battery = 0.02 
          eps_o_mech = 0.14
          eps_o_elec = 0.01
        \stopluacode
        
        \placetable[top][tab:obstacle_value_bdd]{Satisfaction rate for obstacles.}
        {\setupTABLE[c][each][align={right,lohi},frame=off,offset=0pt]
        \setupTABLE[r][1][style=bold,bottomframe=on,boffset=4pt]
        \setupTABLE[r][2][toffset=4pt]
        \setupTABLE[c][1][roffset=4pt]
        \setupTABLE[c][2][loffset=4pt,roffset=4pt]
        \setupTABLE[c][3][loffset=4pt]
        \switchtobodyfont[small]
        \bTABLE
        \bTR \bTD Obstacle                  \eTD \bTD SatRate   \eTD \bTD 1 - SatRate   \eTD \eTR
        \bTR \bTD Diesel Generator Failure  \eTD \bTD $\ctxlua{round2(eps_o_diesel)}$ \eTD \bTD $\ctxlua{round2(1-eps_o_diesel)}$  \eTD \eTR
        \bTR \bTD Primary Power Supply Down \eTD \bTD $\ctxlua{round2(eps_o_primary)}$ \eTD \bTD $\ctxlua{round2(1-eps_o_primary)}$  \eTD \eTR
        \bTR \bTD Power Cabling Failure     \eTD \bTD $\ctxlua{round2(eps_o_cabling)}$ \eTD \bTD $\ctxlua{round2(1-eps_o_cabling)}$ \eTD \eTR
        \bTR \bTD UPS Battery Failure       \eTD \bTD $\ctxlua{round2(eps_o_battery)}$ \eTD \bTD $\ctxlua{round2(1-eps_o_battery)}$   \eTD \eTR
        \bTR \bTD Pump Mechanical Failure   \eTD \bTD $\ctxlua{round2(eps_o_mech)}$ \eTD \bTD $\ctxlua{round2(1-eps_o_mech)}$  \eTD \eTR
        \bTR \bTD Pump Electrical Failure   \eTD \bTD $\ctxlua{round2(eps_o_elec)}$ \eTD \bTD $\ctxlua{round2(1-eps_o_elec)}$ \eTD \eTR
        \eTABLE
        }
        
        For example, let us consider the satisfaction rates summarized in
        \in{Table}[tab:obstacle_value_bdd]. Based on these values, the
        probability of the node {\ss Pump Electrical Failure} is given by:

        \ctxlua{node_elect   = (1-eps_o_elec) * 0 + eps_o_elec * 1}
        \ctxlua{node_mech    = (1-eps_o_mech) * node_elect + eps_o_mech * 1}
        \ctxlua{node_battery = (1-eps_o_battery) * node_mech + eps_o_battery * 1}
        \ctxlua{node_cabling = (1-eps_o_cabling) * node_battery + eps_o_cabling * 1}
        \ctxlua{node_primary = (1-eps_o_primary) * node_cabling + eps_o_primary * 1}
        \ctxlua{node_diesel  = (1-eps_o_diesel) * node_cabling + eps_o_diesel * node_primary}
        
        \startformula
          P_{Pump Electrical Failure} = \ctxlua{round2(1-eps_o_elec)} \times 0 
            + \ctxlua{round2(eps_o_elec)} \times 1 
            = \ctxlua{round3(node_elect)}
        \stopformula

        The probability of the node {\ss Pump Mechanical Failure} is:

        \startformula
          P_{Pump Mechanical Failure} = \ctxlua{round2(1-eps_o_mech)} \times \ctxlua{round3(node_elect)} 
            + \ctxlua{round2(eps_o_mech)} \times 1 
            = \ctxlua{round3(node_mech)}
        \stopformula

        Similarily, we compute the probability for the nodes {\ss UPS Battery Failure},
        {\ss Power Cabling Failure} and {\ss Primary Power Supply Down}:

        \startformula\openup -5pt\startalign[n=1,align=left]
          \NC P_{UPS Battery Failure} = \ctxlua{round2(1-eps_o_battery)} \times \ctxlua{round3(node_mech)} 
            + \ctxlua{round2(eps_o_battery)} \times 1 
            = \ctxlua{round3(node_battery)} \NR
          \NC P_{Power Cabling Failure} = \ctxlua{round2(1-eps_o_cabling)} \times \ctxlua{round3(node_battery)} 
            + \ctxlua{round2(eps_o_cabling)} \times 1 
            = \ctxlua{round3(node_cabling)} \NR
          \NC P_{Primary Power Supply Down} = \ctxlua{round2(1-eps_o_primary)} \times \ctxlua{round3(node_cabling)} 
            + \ctxlua{round2(eps_o_primary)} \times 1 
            = \ctxlua{round3(node_primary)} \NR
        \stopalign\stopformula

        We finally obtain the probability for the root node {\ss Diesel Generator Failure}:

        \startformula
          P_{Diesel Generator Failure} = \ctxlua{round2(1-eps_o_diesel)} \times \ctxlua{round3(node_cabling)} 
            + \ctxlua{round2(eps_o_diesel)} \times \ctxlua{round3(node_primary)}  
            = \ctxlua{round3(node_diesel)}
        \stopformula
        
        \noindent {\bf Step 3: Computing satisfaction rate.} The satisfaction
        rate of an obstacle $O$ is given by the probability that its entailment
        superset is satisfied:
       
        \startformula
          P (O) = Pr  [ES (O)],
        \stopformula
        
        where $Pr [ES(O)]$ denotes the probability that the entailment superset
        $ES (O)$ is satisfied.
        
        The satisfaction rate of a goal $G$ is given by the probability that
        its obstruction superset is not satisfied:
       
        \startformula
          P (G) =  1 - Pr  [OS (G)],
        \stopformula

        where $Pr [OS(O)]$, respectively $Pr [OS(G)]$, denotes the probability
        that the obstruction superset $OS (O)$, respectively $OS (G)$, is
        satisfied.
        
        In our example, we derive the probability of satisfaction for the goal
        \goal{Achieve [Make Up Pump Motor On When Water Requested]} from the
        probability value for the root node of the BDD, that is,

        \startformula
        	P (\text{\goal{Achieve [Make Up Pump Motor On ...]}}) 
            = 1 - \ctxlua{round3(node_diesel)} 
            = \ctxlua{context((1-math.ceil(node_diesel*1000)/1000)*100)}\%
        \stopformula
        
      \stopsubsubsection
    
    \stopsubsection
     
		\subsection[sec:pattern_based_computation]{Pattern-based computation of satisfaction rates}
    
      As an alternative approach to propagation, we may compute the
      satisfaction rate of the obstacle or goal at each propagation step.
      Similarly to the approach presented in the previous section, this
      alternative procedure propagates the satisfaction rate from leaf
      obstacles to root obstacles, then from root obstacles to obstructed leaf
      goals, and finally from leaf goals to root goals. As opposed to the
      previous approach, obstruction supersets are not computed here.
      
      \noindent{\bf Step 1: From leaf obstacles to root obstacles.} For an
      obstacle $O$ refined through two subobstacles $SO_1, SO_2$, the satisfaction
      rate of the parent obstacle is given by:
      
      \startformula
        P(O) = P(SO_1)\times P(SO_2) \times P(O\mid SO_1, SO_2)
      \stopformula
      
      The term $P(O\mid SO_1, SO_2)$ captures weak entailment, as the
      combination of the subobstacles might not entail $O$ (See
      \in{Definition}[def:partial-obstacle-entailment]). This term has to be
      estimated by domain experts and annotate the refinement.
      
      An obstacle OR-refined through two subobstacles is satisfied if one of them is
      satisfied. Therefore, an obstacle OR-refined through two subobstacles is {\it
      not} satisfied if all subobstacle are {\it not} satisfied. For a
      OR-Refinement of the obstacle $O$ into two subobstacles $SO_1, SO_2$ the
      satisfaction rate of $O$ is given by:
      
      \startformula\openup -5pt
        \startalign
          \NC P(O) = 1 - \NC \left[1 - P(SO_1)\times P(O\mid SO_1)\right]\NR
          \NC            \NC \times \left[1 - P(SO_2)\times P(O\mid SO_2)\right],\NR
        \stopalign
      \stopformula
      
      where the terms $P(O\mid SO_i)$ capture weak entailment. 
      
      \noindent{\bf Step 2: From root obstacles to leaf goals.} For an
      obstructed goal $OG$ and the corresponding obstacle $RO$, the
      satisfaction rate is obtained using the following equation:
      
      \startformula
        P(OG) = 1 - P(RO)\times P(\neg OG\mid RO),
      \stopformula
      
      where the term $P(\neg OG\mid RO)$ captures a partial obstruction.
            
      \noindent{\bf Step 3: From leaf goals to top goals.} In the most general
      case, the parent goal is satisfied if the two subgoals are satisfied, or
      if the first is satisfied and sufficient for satisfying the parent, or if
      the second is satisfied and sufficient for satisfying the parent. This
      leads to the following {\it general propagation equation for
      AND-refinements}:
      
      \startformula\openup -5pt
        \startalign
          \NC P (G) = \NC P (SG_1, SG_2) \times P (G \mid SG_1, SG_2)  \NR
          \NC \NC + P (SG_1, \neg SG_2) \times P (G \mid SG_1, \neg SG_2)  \NR
          \NC \NC + P (SG_2, \neg SG_1) \times P (G \mid SG_2, \neg SG_1)  \NR
          \NC \NC + P (\neg SG_1, \neg SG_2) \times P (G \mid \neg SG_1, \neg SG_2) \NR
        \stopalign
      \stopformula
      
      As we focus our attention on a single system, no alternative
      OR-refinements are to be considered. The satisfaction rate of a goal $G$
      given that none of the subgoals is satisfied is then equal to zero;
      thereby $P (G \mid \neg SG_1, \neg SG_2) = 0$. Moreover, if the
      refinement is complete, we have
      
      \startformula
        P (G \mid SG_1, SG_2) = 1
      \stopformula
      
      The AND-propagation equation then reduces to:
      
      \startformula\openup -5pt
        \startalign
          \NC P (G) = \NC P (SG_1, SG_2) \NR
          \NC         \NC + P (SG_1, \neg SG_2) \times P (G \mid SG_1, \neg SG_2) \NR
          \NC         \NC + P (SG_2, \neg SG_1) \times P (G \mid SG_2, \neg SG_1) \NR
        \stopalign
      \stopformula
      
      wher the terms $P(G\mid ...)$ capture that a single subgoal may entail
      the parent goal. Such probabilities are to be estimated by domain experts
      and annotate the refinement.
      
      Depending on the type of refinement and goal, this propagation equation can
      be made further specific. \in{Table}[tab:propagation-rules] gives
      propagation equations for a sample of common refinement patterns known to be
      complete, consistent and minimal \cite[Dar95].
      
      \placetable[top][tab:propagation-rules]
        {Propagation equations for common goal refinement patterns.}
        {\setupTABLE[c][each][align={right,lohi},frame=off,offset=0pt]
        \setupTABLE[r][1][style=bold,bottomframe=on,boffset=4pt]
        \setupTABLE[r][2][toffset=4pt]
        \setupTABLE[c][1][roffset=4pt]
        \setupTABLE[c][2][loffset=4pt]
        \switchtobodyfont[small]
        \bTABLE
          \bTR \bTD Refinement Pattern        \eTD \bTD Propagation Rule \eTD \eTR
          \bTR \bTD Milestone-driven          \eTD \bTD $P(G) = P(SG_1) \times P(SG_2)$                        \eTD \eTR
          \bTR \bTD Case-driven               \eTD \bTD $P(G) = P(CS) \times P(SG_1) + (1–P(CS)) \times P(SG_2)$ \eTD \eTR
          \bTR \bTD Guard introduction        \eTD \bTD $P(G) = P(SG_1) \times P(SG_2) \times P(SG_3)$         \eTD \eTR
          \bTR \bTD Divide-and-conquer        \eTD \bTD $P(G) = P(SG_1) \times P(SG_2)$                        \eTD \eTR
          \bTR \bTD Unmonitoribility-driven   \eTD \bTD $P(G) = P(SG_1) \times P(SG_2)$                        \eTD \eTR
          \bTR \bTD Uncontrollability-driven  \eTD \bTD $P(G) = P(SG_1) \times P(SG_2)$                        \eTD \eTR
        \eTABLE}
      
      For example, for a {\it milestone-driven} refinement \cite[Dar95], the
      satisfaction of a single milestone-based subgoal is not sufficient for
      satisfying the parent goal. The propagation equation therefore reduces to:
      
      \startformula
        P (G) = P (SG_1) × P (SG_2)
      \stopformula
      
      However, for a {\it case-driven} refinement \cite[Dar95], the parent goal
      is satisfied when one of the subgoals is satisfied. The probability of
      satisfying the case condition $CS$, denoted $P(CS)$, equals $P(G\mid
      SG_1,\neg SG_2)$. Therefore, assuming two disjoint cases, the propagation
      equation becomes:
      
      \startformula
        P (G) = P (CS) \times P (SG_1) + (1 - P (CS)) \times P (SG_2) 
      \stopformula
      
      The specific simplification of the general propagation equation thus
      depends on the goal refinement pattern being used. This information is
      available in the annotation of the refinement node \cite[Lam09].
      
    \subsection[sec:compare_propagations]{Discussion}
      
      This section compares the approaches proposed in the two previous
      sections for computing the satisfaction rate of a high-level goal in the
      goal model.
        
      \startluacode
        eps_o_power_supply_failure = 1 - ((1 - (eps_o_diesel * eps_o_primary)) * (1 - eps_o_cabling) * (1 - eps_o_battery))
      \stopluacode
      
      The propagation procedure using obstruction supersets supports dependent
      goals and obstacles. The pattern-based propagation procedure does not. In
      the pattern-based propagation, the computation of satisfaction rate of a
      goal or an obstacle only depends on the refinees whereas in the BDD-based
      propagation the obstruction supersets also capture the refinement
      structure.
      
      \noindent
      For example, consider the goal model fragment in
      \in{Figure}[fig:shared_obstacle]. The satisfaction rate of the obstacle
      \obstacle{No Power Available} is
      $\ctxlua{round3(eps_o_power_supply_failure)}$. With the pattern-based
      propagation procedure, the satisfaction rate of both subgoals is
      $\ctxlua{round3(1 - eps_o_power_supply_failure)}$. The satisfaction rate
      of the parent goal \goal{Achieve [Make Up Water Provided When
      Requested]} is computed using the specialized propagation equation for a {\it
      divide-and-conquer} refinement \cite[Dar95], leading to $\ctxlua{round2(1
      - eps_o_power_supply_failure)} \times \ctxlua{round2(1 -
      eps_o_power_supply_failure)} = \ctxlua{round3((1 -
      eps_o_power_supply_failure) * (1 - eps_o_power_supply_failure))}$. This
      however counts the obstacles twice. In contrast, the obstruction superset
      for the parent goal is $\{\{\text{\obstacle{No Power Available}}\}\}$.
      The probability to satisfy the obstruction superset is
      $\ctxlua{round2(eps_o_power_supply_failure)}$. The satisfaction rate of
      the goal is therefore $\ctxlua{round2(1 - eps_o_power_supply_failure)}$.

      \placefigure[top]
      	[fig:shared_obstacle]
      	{Goal/obstacle model fragment for \goal{Achieve [Make Up Water Provided When Requested]}.}
        {\externalfigure[../images/chap4/shared_obstacle.pdf]}
       
      \indentation The pattern-based propagation procedure appears to be
      finer-grained as it supports weak entailments and weak obstructions.
      These need however to be elicited from domain experts. Using more
      specific propagation equation leads to more precise estimates, in
      particular when the refinement follows the {\it by-case} refinement
      pattern \cite[Dar95].
      
      \noindent For example, consider the (hypothetical) refinement in
      \in{Figure}[fig:by_case]. Given independent obstruction sets, the
      satisfaction rate of the goal \goal{Maintain [Water Level Above LOW]}
      will equal the product of the satisfaction rate of the subgoals. However,
      the refinement with only one subgoal satisfies the partial entailment
      condition. In other words, the probability that \goal{Maintain [Water
      Level Above LOW]} is satisfied is not $0$ when only \goal{Achieve [Water
      Level Above LOW When Alarm Raised]} is satisfied. Using the specific
      propagation equation gives a satisfaction rate for the parent goal that
      will take the weak entailment into account, resulting in an higher
      satisfaction rate.

      \placefigure[top]
      	[fig:by_case]
      	{By-case refinement for \goal{Maintain [Water Level Above LOW]}.}
        {\externalfigure[../images/chap4/by_case.pdf]}
      
      \indentation The main difference between the two propagation procedures
      is about {\it when} most of the computation occurs. With the BDD-based
      propagation technique, most of the computation cost occurs at the
      construction of the obstruction supersets for the considered goal. The
      computation of the probability given an obstruction superset is very
      cheap in comparison. With the pattern-based approach, the cost cannot be
      split in two smaller procedures. In particular,
      
      \startitemize
      
        \item As it will be seen in \in{Chapter}[chap:knowledge-uncertainty],
        the BDD-based approach also enables fast computation of probability
        distributions. To obtain probability distributions, we compute many
        obstruction superset probabilities on the same obstruction superset,
        taking advantage of the separation in two steps.
      
        \item As it will be seen in \in{Chapter}[runtime], the BDD-based
        procedure also enables the runtime monitoring of satisfaction rates as
        the obstruction superset is not computed at runtime.
      
      \stopitemize
      
      \indentation On a randomly generated model with 10.000 goals and 10.000
      obstacles (with 1000 obstruction links), the pattern-based computation
      takes about 13 seconds, whereas the BDD-based computation takes about 18
      seconds. However, computing the probability of the obstruction superset takes
      only 5 milliseconds. Each experiment was performed 80 times and the
      observed variance was very small (below 60 ms for the two propagations,
      and below a tenth of a millisecond for the probability computation). All
      benchmarks were performed using {\it BenchmarkDotNet} \cite[BDNET] on an
      Apple MacBook Pro with a 3 GHz Intel Core i7, 16 GB of 1600 MHz DDR3 Ram,
      and an Apple SSD drive.
      
      In conclusion, the BDD-based procedure appears superior to the
      pattern-based procedure as it is more efficient, thanks to the
      pre-computation of the BDD and to the simpler equations; more general, as
      it does not depend on specific refinement patterns; and requires less
      input from domain experts, as weak entailment and weak obstructions are
      not considered.
      
    % \in{Figure}[fig:nb_goals] shows the mean time to compute the satisfaction
    % rate of a high-level goal on a randomly generated goal/obstacle model.
    % The $y$-axis indicates the mean time to compute the satisfaction rate. The
    % $x$-axis indicates the number of obstacles (top), and the number of goals
    % (bottom). The gray line with circle points shows the time for the
    % BDD-based approach; the orange line with triangular points shows the time
    % for BDD-based approach without accounting the time to build the BDD; the
    % blue line with square points shows the time for the pattern-based
    % approach. Some data points are missing, these corresponds to unrealistic
    % models; e.g. 1000 obstructions with 10 goals and 10 obstacles.
    % 
    % As models are randomly generated, this might not reflect the time
    % required on a real model as the structure is likely to be different.
    % However, it provides useful information to compare the propagation
    % techniques. Each experiment was performed multiple time and the observed
    % variance was very small. All benchmarks were performed using {\it
    % BenchmarkDotNet} \cite[BDNET] on an Apple MacBook Pro with a 3 GHz Intel
    % Core i7, 16 GB of 1600 MHz DDR3 Ram, and an Apple SSD drive.
    % 
    % As we can see on \in{Figure}[fig:nb_goals], it is not always better to
    % use the BDD-based propagation; on some plots, the blue line is lower than
    % the gray line. However, as the orange line shows, if multiple probability
    % computations are required, the BDD-based approach is faster. The
    % computation time of a satisfaction rates increase with the number of
    % obstacles, as expected. The computation time of a satisfaction rate also
    % increase with the number of goals, but the computation time is constant
    % once the obstruction superset is built (for the BDD-based approach).
    %
    % \placefigure[page]
    % 	[fig:nb_goals]
    % 	{Mean time to compute a satisfaction rate in a random goal/obstacle model.}
    %   {\startcombination[1*2]
    %     {\externalfigure[../images/chap4/nb_obstacles.pdf]}{}
    %     {\externalfigure[../images/chap4/nb_goals.pdf]}{}
    %   \stopcombination
    %   }
        
  \startsection
    [reference=sec:indentifying_most_critical_obstacles,
     title={Highlighting most critical and likely obstacles}]

    This section shows how likely and critical risks are pointed out based on
    the estimated statisfaction rates for leaf obstacles (see
    \in{Section}[sec:estimating_satrate]) and the satisfaction rate of the
    obstructed high-level goals, as computed by one of the two propagation
    procedures (see \in{Section}[sec:computing_satrate]). These likely and
    critical obstacles should be resolved in the next phase of obstacle control.
    
    The criticality of an obstacle is accordingly determined as the loss in
    satisfaction rate of some important high-level goals from the goal model.
    In our running example, the obstacle \obstacle{UPS Battery Failure} causes,
    alone, a loss of $0.011$ for the high-level goal \goal{Achieve [Make Up
    Water Provided When Loss Of Cooling]}.
  
    An obstacle is said to be {\it critical} for a goal if it causes the
    satisfaction rate of this goal to fall below the required satisfaction rate.
  
    \startdefinition[def:critical_obstacle]{Critical obstacle}
  
      A probabilistic obstacle $O$ is {\it critical} for a goal $G$ if obstacle
      $O$ results in a goal satisfaction rate such that $P(G) < RSR(G)$, i.e.
      $SV(G) > 0$. (As a recall, $SV(G) = RSR(G) - P(G)$, see
      \in{Definition}[dfn:vs].)
  
    \stopdefinition
  
    An obstacle is said {\it acceptable} for a goal if it results in a
    satisfaction rate for this goal higher than its required threshold.
  
    \startdefinition{Acceptable obstacle}
  
      A probabilistic obstacle $O$ is {\it acceptable} for a goal $G$ if
      obstacle $O$ does not result in a goal satisfaction rate such that $P(G)
      < RSR(G)$.
  
    \stopdefinition
  
    An obstacle is said to be {\it tolerable} if the goal's satisfaction rate
    falls below some tolerable satisfaction rate but still above the required
    satisfaction rate.
  
    \startdefinition{Tolerable obstacle}
  
      A probabilistic obstacle $O$ is {\it tolerable} for a goal $G$ if it
      results in a satisfaction rate for the goal $G$ such that $TSR(G) < P(G) <
      RSR(G)$.
  
    \stopdefinition
  
    \noindent To evaluate obstacles criticality, we may proceed in two ways:
  
    \startitemize

      \item {\bf Global impact analysis:} the satisfaction rate of {\it all}
      leaf obstacles are together propagated bottom-up in the goal graph to see
      how much the resulting statisfaction rate of higher-level goals deviates
      from their required satisfaction rate.

      \item {\bf Local impact analysis:} the consequence of a {\it single} leaf
      obstacle is evaluated by up-propagation of the satisfaction rate of this
      leaf obstacles, all other leaf obstacles being assigned a probability of
      $0$ (meaning that they are all assumed to never happen).
  
    \stopitemize
  
    In-between, we can evaluate the consequences of a {\it combination} of leaf
    obstacles. By iterating on the size of the combinations, we move from local
    impact analysis to global impact analysis.
  
    For example, global impact analysis reveals that the root goal
    \goal{Achieve [Make Up Water Provided When Loss Of Cooling]} is satisfied
    in $80.31\%$ of cases when all obstacles are considered. Local impact
    analysis reveals that the obstacle \obstacle{UPS Battery Failure} causes
    the satisfaction rate of the root goal \goal{Achieve [Make Up Water
    Provided When Loss Of Cooling]} to fall from $1$ to $.989$. With a required
    satisfaction rate of $.99$, the obstacle \obstacle{UPS Battery Failure} is
    critical for \goal{Achieve [Make Up Water Provided When Loss Of Cooling]}.
    
    The most critical obstacle for a goal is the obstacle that maximize the
    violation severity.
  
    \startdefinition{Most critical obstacle}
  
      A probabilistic obstacle $O$ is the {\it most critical obstacle} for a
      goal $G$ if obstacle $O$ is critical and no other obstacle results in a
      higher violation severity $SV(G)$.
  
    \stopdefinition
    
    A set of obstacle is {\it critical} if the obstacles together causes the
    violation severity to drop below $0$. A set of obstacle is {\it the most
    critical set of obstacles} if no other set of obstacles of the same size
    causes a higher violation severity.
    
  % \startdefinition{Severity of the consequences}
  % 
  %   The {\it severity of the consequences} for an obstacle $O$, denoted
  %   $SC(O)$, is defined as the weighted sum of the resulting violation
  %   severities for the root goals, that is,
  %  
  %   \startformula
  %     SC(O) = \sum_{G \in Roots} SV(G) \times Weight(G)
  %   \stopformula
  %  
  % \stopdefinition
  % 
  % where the obstacle $O$ results in a violation severity $SV(G)$ for the
  % root goal $G$ and $Weight(G)$ corresponds to the relative priority
  % assigned to the root goal $G$.
  
  
    Obstacle assessment can be presented using a {\it violation diagram}. A
    violation diagram somewhat correspond to a risk matrix \cite[Ayy14]; A risk
    matrix groups risk likelihood and criticality in discrete categories. In a
    violation diagram, the risks are represented in a two-dimensional plot
    showing the violation severity for a high-level goal and probability of
    occurence of a leaf obstacle combination.

    In a violation diagram, the $x$-axis represents the probability of leaf
    obstacle combination occurence; it is the product of the estimated
    satisfaction rate of the leaf obstacles in the combination. The $y$-axis
    captures the violation severity for the goal considering the leaf obstacles
    in the combination.
  
    \in{Figure}[fig:violation_diagram_single_value] shows a violation diagram
    for the goal \goal{Achieve [Make Up Water Provided When Loss Of Cooling]}
    with the leaf obstacles from the obstacle model; here, the combinations
    contains a single leaf obstacle. We can see that most of
    the obstacles taken alone have a zero violation severity; these are
    therefore not critical for the system. Three obstacles are however
    critical, namely \obstacle{Pump Mechanical Failure}, \obstacle{UPS Battery
    Failure}, and \obstacle{Power Cabling Failure}. These critical obstacles
    should be resolved in the next phase.
  
    \placefigure[here]
    	[fig:violation_diagram_single_value]
    	{Violation Diagram for \goal{Achieve [Make Up Water Provided When Loss Of Cooling]}.}
      {
        \externalfigure[../images/chap4/violation_diagram_single_value.pdf]
      }
  
    Criticality assessment should be an iterative process. Once the most likely
    and critical obstacle combinations of size $i$ are resolved, a new
    violation diagram should be produced with obstacle combinations of size
    $i+1$. The process ends when no obstacle combination is found critical and
    likely.
  
    \in{Figure}[fig:violation_diagram_single_value2] shows a violation diagram
    for the goal \goal{Achieve [Make Up Water Provided When Loss Of Cooling]}
    considering pairs of obstacles, i.e. combinations of size $2$. Among the 91
    pairs of leaf obstacles, 39 are critical; there are 36 pairs that contains
    a critical obstacle identified with the previous violation diagram in
    \in{Figure}[fig:violation_diagram_single_value]. 3 pairs of leaf obstacles
    are critical and do not contain an obstacle critical alone. Those are
    (\obstacle{Pump Electrical Failure} and \obstacle{Alarm Not Raised And Low
    Water}), (\obstacle{Pump Electrical Failure}, \obstacle{Valve Mechanical
    Failure}), and (\obstacle{Pump Electrical Failure}, \obstacle{Valve
    Electrical Failure}). In our experience, we observed that most of the
    likely and critical obstacle combinations are caused only by a subset of
    these.
  
    \placefigure[bottom]
    	[fig:violation_diagram_single_value2]
    	{Violation Diagram for \goal{Achieve [Make Up Water Provided When Loss Of Cooling]} with pair of obstacles.}
      {
        \externalfigure[../images/chap4/violation_diagram_single_value2.pdf]
      }
    
    \indentation There is a multi-criteria optimization problem here as we are
    looking for minimal sets of leaf obstacles that maximize the severity of
    goal violations. To solve the optimization problem, we can naïvely generate
    all possible leaf obstacle combinations. The violation severity $SV (G)$ is
    then computed for the root goal $G$. Most critical combinations are
    identified by sorting the leaf obstacle combinations by violation severity.

    Note that a \quote{most critical obstacle combination} is {\it Pareto
    efficient} for the size of the combination; that is no other combination
    cause a higher violation severity. The set of leaf obstacle combinations
    that maximizes the severity defines a {\it Pareto front}; it is the set
    containing the most critical obstacle combinations. Efficient algorithms
    for generating {\it Pareto fronts} are available \cite[Bor01,Kun75]. These
    algorithms and the specific structure of our problem suggests that our
    generation of leaf obstacle combinations and their ranking by severity
    could thereby be optimized in order to scale up for larger systems.
  
    The techniques presented in this chapter consider a single high-level goal
    only. In practice, several high-level goals might be competing. In such
    situations, the satisfaction rate of these high-level goals are to be
    combined using a normalized weighted sum in order to apply the techniques
    as if there was only a single aggregated high-level goal. The weights in
    this aggregation correspond to the relative priority of those high-level
    goals.
    

  \stopsection
  
  \startsection[title={Summary}]
  
    This chapter showed how likely and critical risks are pointed out to focus
    the resolution step on important obstacle combinations. The satisfaction
    rates of leaf obstacles are first estimated by domain experts, possibly
    multiple ones to be combined in order to produce more accurate estimates.
    The leaf estimates are then up-propagated through the obstacle and goal
    models to compute the satisfaction rate of important high-level goals. The
    chapter presented two propagation techniques: a BDD-based approach and a
    pattern-based one. The BDD-based approach is more efficient, more general
    and requires less input from domain experts; the Pattern-based approach
    provides finer-grained estimates. The computed satisfaction rate of the
    high-level goals is then compared with their respective required
    satisfaction rates. Obstacles causing the computed satisfaction rate to
    fall below the required satisfaction rate of these high-level goals are the
    critical obstacles to be resolved in the next phase of risk control.
    Violation diagrams captures likely and critical obstacle combinations.
    
    The techniques presented in this chapter provides a basis for determining
    most appropriate countermeasures, as seen in the next chapter.
  
  \stopsection

\stopcomponent
